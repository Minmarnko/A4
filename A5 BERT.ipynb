{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bSz5jzj61nHc"
      },
      "source": [
        "# BERT\n",
        "\n",
        "We shall implement BERT.  For this tutorial, you may want to first look at my Transformers tutorial to get a basic understanding of Transformers. \n",
        "\n",
        "For BERT, the main difference is on how we process the datasets, i.e., masking.   Aside from that, the backbone model is still the Transformers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in c:\\users\\jue\\desktop\\nlp\\a4\\.venv\\lib\\site-packages (2.6.0+cu118)\n",
            "Requirement already satisfied: torchvision in c:\\users\\jue\\desktop\\nlp\\a4\\.venv\\lib\\site-packages (0.21.0+cu118)\n",
            "Requirement already satisfied: torchaudio in c:\\users\\jue\\desktop\\nlp\\a4\\.venv\\lib\\site-packages (2.6.0+cu118)\n",
            "Requirement already satisfied: filelock in c:\\users\\jue\\desktop\\nlp\\a4\\.venv\\lib\\site-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\jue\\desktop\\nlp\\a4\\.venv\\lib\\site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\jue\\desktop\\nlp\\a4\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\jue\\desktop\\nlp\\a4\\.venv\\lib\\site-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in c:\\users\\jue\\desktop\\nlp\\a4\\.venv\\lib\\site-packages (from torch) (2024.12.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\jue\\desktop\\nlp\\a4\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jue\\desktop\\nlp\\a4\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\jue\\desktop\\nlp\\a4\\.venv\\lib\\site-packages (from torchvision) (2.2.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\jue\\desktop\\nlp\\a4\\.venv\\lib\\site-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jue\\desktop\\nlp\\a4\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-8kZmr4ItGUj"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Jue\\Desktop\\NLP\\A4\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import re\n",
        "from   random import *\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from datasets import load_dataset\n",
        "import spacy\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "# Set device as GPU if available, else set to CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = 'cpu'\n",
        "print(device)\n",
        "\n",
        "#make our work comparable if restarted the kernel\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data\n",
        "\n",
        "For simplicity, we shall use very simple data like this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Jue\\Desktop\\NLP\\A4\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Jue\\.cache\\huggingface\\hub\\datasets--embedding-data--QQP_triplets. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n",
            "Generating train split: 100%|██████████| 101762/101762 [00:00<00:00, 298580.25 examples/s]\n"
          ]
        }
      ],
      "source": [
        "# Load a portion of the WikiAnswers dataset\n",
        "dataset = load_dataset(\"embedding-data/QQP_triplets\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Put 'query', 'pos' and 'neg' from each sample into a list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = []\n",
        "for i in range(len(dataset['train'])):\n",
        "    all_sents = [dataset['train'][i]['set']['query']] + dataset['train'][i]['set']['pos'] + dataset['train'][i]['set']['neg']\n",
        "    text.extend(all_sents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2995804"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(text) #number of sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = [x.lower() for x in text] #lower case\n",
        "text = [re.sub(\"[.,!?\\\\-]\", '', x) for x in text] #clean all symbols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "why in india do we not have one on one political debate as in usa _____\n",
            "['why', 'in', 'india', 'do', 'we', 'not', 'have', 'one', 'on', 'one', 'political', 'debate', 'as', 'in', 'usa']\n"
          ]
        }
      ],
      "source": [
        "for sentence in text:\n",
        "    print(sentence, \"_____\")\n",
        "    words = sentence.split()\n",
        "    print(words)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "### limit datasize\n",
        "text_lim = text[0:1000000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'why cant we have a public debate between politicians in india like the one in us'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_lim[1]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Making vocabs\n",
        "\n",
        "Before making the vocabs, let's remove all question marks and perios, etc, then turn everything to lowercase, and then simply split the text. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = {} # to save parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "AhX8b1ydtrVf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab size : 73276\n"
          ]
        }
      ],
      "source": [
        "# combine everything into one to make vocabs\n",
        "word_list = list(set(\" \".join(text_lim).split()))\n",
        "word2id = {'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, '[UNK]': 4}  #special tokens.\n",
        "\n",
        "#create the word2id\n",
        "for i, w in enumerate(word_list):\n",
        "    word2id[w] = i + 5  #because 0-3 are already occupied\n",
        "    id2word = {i: w for i, w in enumerate(word2id)}\n",
        "    vocab_size = len(word2id)\n",
        "print(f'Vocab size : {vocab_size}')\n",
        "#list of all tokens for whole text_lim\n",
        "token_list = list()\n",
        "for sentence in text_lim:\n",
        "    arr = [word2id[word] for word in sentence.split()]\n",
        "    token_list.append(arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "data['vocab_size'] = vocab_size\n",
        "data['word2id'] = word2id"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data loader\n",
        "\n",
        "We gonna make dataloader.  Inside here, we need to make two types of embeddings: **token embedding** and **segment embedding**\n",
        "\n",
        "1. **Token embedding** - Given “The cat is walking. The dog is barking”, we add [CLS] and [SEP] >> “[CLS] the cat is walking [SEP] the dog is barking”. \n",
        "\n",
        "2. **Segment embedding**\n",
        "A segment embedding separates two sentences, i.e., [0 0 0 0 1 1 1 1 ]\n",
        "\n",
        "3. **Masking**\n",
        "As mentioned in the original paper, BERT randomly assigns masks to 15% of the sequence. In this 15%, 80% is replaced with masks, while 10% is replaced with random tokens, and the rest 10% is left as is.  Here we specified `max_pred` \n",
        "\n",
        "4. **Padding**\n",
        "Once we mask, we will add padding. For simplicity, here we padded until some specified `max_len`. \n",
        "\n",
        "Note:  `positive` and `negative` are just simply counts to keep track of the batch size.  `positive` refers to two sentences that are really next to one another."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 6\n",
        "max_mask   = 5  # max masked tokens when 15% exceed, it will only be max_pred\n",
        "max_len    = 1000 # maximum of length to be padded; "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "data['batch_size'] = batch_size\n",
        "data['max_mask'] = max_mask\n",
        "data['max_len'] = max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TtyOOmRntu8w"
      },
      "outputs": [],
      "source": [
        "def make_batch():\n",
        "    batch = []\n",
        "    positive = negative = 0  #count of batch size;  we want to have half batch that are positive pairs (i.e., next sentence pairs)\n",
        "    while positive != batch_size/2 or negative != batch_size/2:\n",
        "        \n",
        "        #randomly choose two sentence so we can put [SEP]\n",
        "        tokens_a_index, tokens_b_index= randrange(len(text_lim)), randrange(len(text_lim))\n",
        "        #retrieve the two sentences\n",
        "        tokens_a, tokens_b= token_list[tokens_a_index], token_list[tokens_b_index]\n",
        "\n",
        "        #1. token embedding - append CLS and SEP\n",
        "        input_ids = [word2id['[CLS]']] + tokens_a + [word2id['[SEP]']] + tokens_b + [word2id['[SEP]']]\n",
        "\n",
        "        #2. segment embedding - [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
        "        segment_ids = [0] * (1 + len(tokens_a) + 1) + [1] * (len(tokens_b) + 1)\n",
        "\n",
        "        #3. mask language modeling\n",
        "        #masked 15%, but should be at least 1 but does not exceed max_mask\n",
        "        n_pred =  min(max_mask, max(1, int(round(len(input_ids) * 0.15))))\n",
        "        #get the pos that excludes CLS and SEP and shuffle them\n",
        "        cand_maked_pos = [i for i, token in enumerate(input_ids) if token != word2id['[CLS]'] and token != word2id['[SEP]']]\n",
        "        shuffle(cand_maked_pos)\n",
        "        masked_tokens, masked_pos = [], []\n",
        "        #simply loop and change the input_ids to [MASK]\n",
        "        for pos in cand_maked_pos[:n_pred]:\n",
        "            masked_pos.append(pos)  #remember the position\n",
        "            masked_tokens.append(input_ids[pos]) #remember the tokens\n",
        "            #80% replace with a [MASK], but 10% will replace with a random token\n",
        "            if random() < 0.1:  # 10%\n",
        "                index = randint(0, vocab_size - 1) # random index in vocabulary\n",
        "                input_ids[pos] = word2id[id2word[index]] # replace\n",
        "            elif random() < 0.9:  # 80%\n",
        "                input_ids[pos] = word2id['[MASK]'] # make mask\n",
        "            else:  #10% do nothing\n",
        "                pass\n",
        "\n",
        "        # pad the input_ids and segment ids until the max len\n",
        "        n_pad = max_len - len(input_ids)\n",
        "        input_ids.extend([0] * n_pad)\n",
        "        segment_ids.extend([0] * n_pad)\n",
        "\n",
        "        # pad the masked_tokens and masked_pos to make sure the lenth is max_mask\n",
        "        if max_mask > n_pred:\n",
        "            n_pad = max_mask - n_pred\n",
        "            masked_tokens.extend([0] * n_pad)\n",
        "            masked_pos.extend([0] * n_pad)\n",
        "\n",
        "        #check if first sentence is really comes before the second sentence\n",
        "        #also make sure positive is exactly half the batch size\n",
        "        if tokens_a_index + 1 == tokens_b_index and positive < batch_size / 2:\n",
        "            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, True]) # IsNext\n",
        "            positive += 1\n",
        "        elif tokens_a_index + 1 != tokens_b_index and negative < batch_size/2:\n",
        "            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, False]) # NotNext\n",
        "            negative += 1\n",
        "            \n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Q7_HC-Y0jC3K"
      },
      "outputs": [],
      "source": [
        "batch = make_batch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#len of batch\n",
        "len(batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([6, 1000]),\n",
              " torch.Size([6, 1000]),\n",
              " torch.Size([6, 5]),\n",
              " torch.Size([6, 5]),\n",
              " torch.Size([6]))"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#we can deconstruct using map and zip\n",
        "input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(*batch))\n",
        "input_ids.shape, segment_ids.shape, masked_tokens.shape, masked_pos.shape, isNext.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model\n",
        "\n",
        "Recall that BERT only uses the encoder.\n",
        "\n",
        "BERT has the following components:\n",
        "\n",
        "- Embedding layers\n",
        "- Attention Mask\n",
        "- Encoder layer\n",
        "- Multi-head attention\n",
        "- Scaled dot product attention\n",
        "- Position-wise feed-forward network\n",
        "- BERT (assembling all the components)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.1 Embedding\n",
        "\n",
        "Here we simply generate the positional embedding, and sum the token embedding, positional embedding, and segment embedding together.\n",
        "\n",
        "<img src = \"figures/BERT_embed.png\" width=500>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Embedding(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Embedding, self).__init__()\n",
        "        self.tok_embed = nn.Embedding(vocab_size, d_model)  # token embedding\n",
        "        self.pos_embed = nn.Embedding(max_len, d_model)      # position embedding\n",
        "        self.seg_embed = nn.Embedding(n_segments, d_model)  # segment(token type) embedding\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, x, seg):\n",
        "        # x, seg: (bs, len)\n",
        "        seq_len = x.size(1)\n",
        "        pos = torch.arange(seq_len, dtype=torch.long, device=self.device)\n",
        "        pos = pos.unsqueeze(0).expand_as(x)  # (len,) -> (bs, len)\n",
        "        embedding = self.tok_embed(x) + self.pos_embed(pos) + self.seg_embed(seg)\n",
        "        return self.norm(embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.2 Attention mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "s1PGksqBNuZM"
      },
      "outputs": [],
      "source": [
        "def get_attn_pad_mask(seq_q, seq_k):\n",
        "    batch_size, len_q = seq_q.size()\n",
        "    batch_size, len_k = seq_k.size()\n",
        "    # eq(zero) is PAD token\n",
        "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)  # batch_size x 1 x len_k(=len_q), one is masking\n",
        "    return pad_attn_mask.expand(batch_size, len_q, len_k)  # batch_size x len_q x len_k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing the attention mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([6, 1000, 1000])\n"
          ]
        }
      ],
      "source": [
        "print(get_attn_pad_mask(input_ids, input_ids).shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.3 Encoder\n",
        "\n",
        "The encoder has two main components: \n",
        "\n",
        "- Multi-head Attention\n",
        "- Position-wise feed-forward network\n",
        "\n",
        "First let's make the wrapper called `EncoderLayer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.enc_self_attn = MultiHeadAttention()\n",
        "        self.pos_ffn       = PoswiseFeedForwardNet()\n",
        "\n",
        "    def forward(self, enc_inputs, enc_self_attn_mask):\n",
        "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask) # enc_inputs to same Q,K,V\n",
        "        enc_outputs = self.pos_ffn(enc_outputs) # enc_outputs: [batch_size x len_q x d_model]\n",
        "        return enc_outputs, attn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's define the scaled dot attention, to be used inside the multihead attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ScaledDotProductAttention, self).__init__()\n",
        "\n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k) # scores : [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
        "        scores.masked_fill_(attn_mask, -1e9) # Fills elements of self tensor with value where mask is one.\n",
        "        attn = nn.Softmax(dim=-1)(scores)\n",
        "        context = torch.matmul(attn, V)\n",
        "        return context, attn "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's define the parameters first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_layers = 6    # number of Encoder of Encoder Layer\n",
        "n_heads  = 8    # number of heads in Multi-Head Attention\n",
        "d_model  = 768  # Embedding Size\n",
        "d_ff = 768 * 4  # 4*d_model, FeedForward dimension\n",
        "d_k = d_v = 64  # dimension of K(=Q), V\n",
        "n_segments = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "data['n_layers'] = n_layers\n",
        "data['n_heads'] = n_heads\n",
        "data['d_model'] = d_model\n",
        "data['d_ff'] = d_ff\n",
        "data['d_k'] = d_k\n",
        "data['d_v'] = d_v\n",
        "data['n_segments'] = n_segments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here is the Multiheadattention."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.W_Q = nn.Linear(d_model, d_k * n_heads).to(device)\n",
        "        self.W_K = nn.Linear(d_model, d_k * n_heads).to(device)\n",
        "        self.W_V = nn.Linear(d_model, d_v * n_heads).to(device)\n",
        "\n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        # q: [batch_size x len_q x d_model], k: [batch_size x len_k x d_model], v: [batch_size x len_k x d_model]\n",
        "        residual, batch_size = Q, Q.size(0)\n",
        "        # (B, S, D) -proj-> (B, S, D) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n",
        "        q_s = self.W_Q(Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)  # q_s: [batch_size x n_heads x len_q x d_k]\n",
        "        k_s = self.W_K(K).view(batch_size, -1, n_heads, d_k).transpose(1, 2)  # k_s: [batch_size x n_heads x len_k x d_k]\n",
        "        v_s = self.W_V(V).view(batch_size, -1, n_heads, d_v).transpose(1, 2)  # v_s: [batch_size x n_heads x len_k x d_v]\n",
        "\n",
        "        attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1).to(device)  # attn_mask : [batch_size x n_heads x len_q x len_k]\n",
        "\n",
        "        # context: [batch_size x n_heads x len_q x d_v], attn: [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
        "        context, attn = ScaledDotProductAttention()(q_s, k_s, v_s, attn_mask)\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, n_heads * d_v)\n",
        "        output = nn.Linear(n_heads * d_v, d_model).to(device)(context)\n",
        "        return nn.LayerNorm(d_model).to(device)(output + residual), attn  # output: [batch_size x len_q x d_model]\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here is the PoswiseFeedForwardNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PoswiseFeedForwardNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PoswiseFeedForwardNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # (batch_size, len_seq, d_model) -> (batch_size, len_seq, d_ff) -> (batch_size, len_seq, d_model)\n",
        "        return self.fc2(F.gelu(self.fc1(x)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.4 Putting them together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "OZ0TJ84W4SZw"
      },
      "outputs": [],
      "source": [
        "class BERT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERT, self).__init__()\n",
        "        self.embedding = Embedding().to(device)\n",
        "        self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)])\n",
        "        self.fc = nn.Linear(d_model, d_model).to(device)\n",
        "        self.activ = nn.Tanh()\n",
        "        self.linear = nn.Linear(d_model, d_model).to(device)\n",
        "        self.norm = nn.LayerNorm(d_model).to(device)\n",
        "        self.classifier = nn.Linear(d_model, 2).to(device)\n",
        "        # decoder is shared with embedding layer\n",
        "        embed_weight = self.embedding.tok_embed.weight\n",
        "        n_vocab, n_dim = embed_weight.size()\n",
        "        self.decoder = nn.Linear(n_dim, n_vocab, bias=False).to(device)\n",
        "        self.decoder.weight = embed_weight\n",
        "        self.decoder_bias = nn.Parameter(torch.zeros(n_vocab)).to(device)\n",
        "\n",
        "    def forward(self, input_ids, segment_ids, masked_pos):\n",
        "        input_ids = input_ids.to(self.embedding.tok_embed.weight.device)\n",
        "        segment_ids = segment_ids.to(self.embedding.tok_embed.weight.device)\n",
        "        masked_pos = masked_pos.to(self.embedding.tok_embed.weight.device)\n",
        "\n",
        "        output = self.embedding(input_ids, segment_ids)\n",
        "        enc_self_attn_mask = get_attn_pad_mask(input_ids, input_ids)\n",
        "        for layer in self.layers:\n",
        "            output, enc_self_attn = layer(output, enc_self_attn_mask)\n",
        "        # output : [batch_size, len, d_model], attn : [batch_size, n_heads, d_mode, d_model]\n",
        "        \n",
        "        # 1. predict next sentence\n",
        "        # it will be decided by first token(CLS)\n",
        "        h_pooled   = self.activ(self.fc(output[:, 0])) # [batch_size, d_model]\n",
        "        logits_nsp = self.classifier(h_pooled) # [batch_size, 2]\n",
        "\n",
        "        # 2. predict the masked token\n",
        "        masked_pos = masked_pos[:, :, None].expand(-1, -1, output.size(-1)) # [batch_size, max_pred, d_model]\n",
        "        h_masked = torch.gather(output, 1, masked_pos) # masking position [batch_size, max_pred, d_model]\n",
        "        h_masked  = self.norm(F.gelu(self.linear(h_masked)))\n",
        "        logits_lm = self.decoder(h_masked) + self.decoder_bias # [batch_size, max_pred, n_vocab]\n",
        "\n",
        "        return output, logits_lm, logits_nsp"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UAG3SEP4UbU",
        "outputId": "bc6f202f-df37-4fac-843c-fb86bdb777b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 00 loss = 107.313850\n",
            "Time: 0m 23s\n",
            "Epoch: 10 loss = 87.021622\n",
            "Time: 6m 25s\n",
            "Epoch: 20 loss = 56.587009\n",
            "Time: 10m 5s\n",
            "Epoch: 30 loss = 43.971119\n",
            "Time: 10m 19s\n",
            "Epoch: 40 loss = 38.193958\n",
            "Time: 10m 42s\n",
            "Epoch: 50 loss = 38.287357\n",
            "Time: 13m 2s\n",
            "Epoch: 60 loss = 36.306377\n",
            "Time: 11m 50s\n",
            "Epoch: 70 loss = 38.242966\n",
            "Time: 10m 21s\n",
            "Epoch: 80 loss = 28.618801\n",
            "Time: 10m 17s\n",
            "Epoch: 90 loss = 19.151419\n",
            "Time: 11m 48s\n",
            "Training Time: 104m 55s\n"
          ]
        }
      ],
      "source": [
        "num_epoch = 100\n",
        "model = BERT()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "total_start = time.time()\n",
        "start_time = time.time()\n",
        "train_losses = []\n",
        "for epoch in range(num_epoch):\n",
        "    # if (epoch - 1) % 10 == 0:\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    batch = make_batch()\n",
        "    # batch = batch.to(device)\n",
        "    input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(*batch))\n",
        "    input_ids = input_ids.to(device)\n",
        "    segment_ids = segment_ids.to(device)\n",
        "    masked_tokens = masked_tokens.to(device)\n",
        "    masked_pos = masked_pos.to(device)\n",
        "    isNext = isNext.to(device)\n",
        "    \n",
        "    _, logits_lm, logits_nsp = model(input_ids, segment_ids, masked_pos)    \n",
        "    #logits_lm: (bs, max_mask, vocab_size) ==> (6, 5, 34)\n",
        "    #logits_nsp: (bs, yes/no) ==> (6, 2)\n",
        "\n",
        "    #1. mlm loss\n",
        "    #logits_lm.transpose: (bs, vocab_size, max_mask) vs. masked_tokens: (bs, max_mask)\n",
        "    loss_lm = criterion(logits_lm.transpose(1, 2), masked_tokens) # for masked LM\n",
        "    loss_lm = (loss_lm.float()).mean()\n",
        "    #2. nsp loss\n",
        "    #logits_nsp: (bs, 2) vs. isNext: (bs, )\n",
        "    loss_nsp = criterion(logits_nsp, isNext) # for sentence classification\n",
        "    \n",
        "    #3. combine loss\n",
        "    loss = loss_lm + loss_nsp\n",
        "    train_losses.append(loss)\n",
        "    if epoch % 10 == 0:\n",
        "        end_time = time.time()\n",
        "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "        start_time = time.time()\n",
        "        \n",
        "        print('Epoch:', '%02d' % (epoch), 'loss =', '{:.6f}'.format(loss))\n",
        "        print(f'Time: {epoch_mins}m {epoch_secs}s')\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "total_end = time.time()\n",
        "total_min, total_sec = epoch_time(total_start, total_end)\n",
        "print(f'Training Time: {total_min}m {total_sec}s')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting matplotlib\n",
            "  Using cached matplotlib-3.10.0-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib)\n",
            "  Using cached contourpy-1.3.1-cp311-cp311-win_amd64.whl.metadata (5.4 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib)\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib)\n",
            "  Downloading fonttools-4.56.0-cp311-cp311-win_amd64.whl.metadata (103 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
            "  Using cached kiwisolver-1.4.8-cp311-cp311-win_amd64.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: numpy>=1.23 in c:\\users\\jue\\desktop\\nlp\\a4\\.venv\\lib\\site-packages (from matplotlib) (2.2.3)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\jue\\desktop\\nlp\\a4\\.venv\\lib\\site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\jue\\desktop\\nlp\\a4\\.venv\\lib\\site-packages (from matplotlib) (11.1.0)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
            "  Using cached pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jue\\desktop\\nlp\\a4\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\jue\\desktop\\nlp\\a4\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Using cached matplotlib-3.10.0-cp311-cp311-win_amd64.whl (8.0 MB)\n",
            "Using cached contourpy-1.3.1-cp311-cp311-win_amd64.whl (219 kB)\n",
            "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.56.0-cp311-cp311-win_amd64.whl (2.2 MB)\n",
            "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
            "   ----------------------- ---------------- 1.3/2.2 MB 7.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.2/2.2 MB 7.3 MB/s eta 0:00:00\n",
            "Using cached kiwisolver-1.4.8-cp311-cp311-win_amd64.whl (71 kB)\n",
            "Using cached pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
            "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
            "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.56.0 kiwisolver-1.4.8 matplotlib-3.10.0 pyparsing-3.2.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_losses(losses):\n",
        "    # Transfer tensor data from GPU to CPU\n",
        "    losses = [loss.item() for loss in losses]\n",
        "\n",
        "    plt.plot(losses, label='Training Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Loss Over Epochs')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAbOBJREFUeJzt3Qd4k+XaB/C7u7RAmS17741sGaKgCKgIqEdFRUVxgNuj4kBFEff2gBMcII5PUBBBluy9995QyhAKLd35rv+TPOmbNkmTNE3S9P87V07TJE3fvK3k7j2eJ8RkMpmEiIiIKEiF+vsAiIiIiIoSgx0iIiIKagx2iIiIKKgx2CEiIqKgxmCHiIiIghqDHSIiIgpqDHaIiIgoqDHYISIioqDGYIeIiIiCGoMdogB19913S506dTz62ldeeUVCQkK8fkxErvzenT592t+HQmSDwQ6Rm/CPuSuXf/75R0pqkFa6dGkpDrBbzvfffy89evSQcuXKSUxMjLRs2VLGjBkjKSkpEqjBhKNLYmKivw+RKCCF+/sAiIobvDkafffddzJ37tx8tzdt2rRQ3+fLL7+UnJwcj772xRdflOeee65Q3z/YZWdny+233y4///yzdO/eXQUSCHaWLFkir776qvzyyy8yb948SUhIkEAzfvx4uwElAjYiyo/BDpGb7rjjDpvPV65cqYKdvLfnlZqaqt5MXRUREeHxMYaHh6sLOfb222+rQOfpp5+Wd955x3r78OHD5ZZbbpEbb7xRZan++usvnx6XK78nN910k1SqVMlnx0RU3LGMRVQEevbsKS1atJB169apEgnevJ5//nl13++//y79+/eXatWqSVRUlNSvX19ee+01lWlw1rNz8OBBVap499135YsvvlBfh6/v0KGDrFmzpsCeHXw+cuRImT59ujo2fG3z5s1l9uzZ+Y4fJbj27dtLdHS0+j6ff/651/uAkDlp166dlCpVSr1xI1g8duyYzWNQlrnnnnukRo0a6nirVq0qAwYMUOdCW7t2rfTp00c9B56rbt26cu+99zr93pcuXVIBTqNGjWTcuHH57r/++utl6NCh6twgmIXrrrtO6tWrZ/f5unTpos6X0Q8//GB9fRUqVJBbb71Vjhw54vLvSWHg54ef1U8//aSer0qVKhIbGys33HBDvmNw9WcBO3fuVIFg5cqV1WMbN24sL7zwQr7HnTt3Tv3+ItMUFxenfoYI4ozwB0K3bt3UY5ClwnN547UT2cM//YiKyJkzZ6Rv377qTQ5vHrocMmnSJPWP+5NPPqk+LliwQEaPHi3Jyck2GQZHpkyZIhcuXJAHHnhAvaEhQzFo0CDZv39/gdmgpUuXym+//SYPP/ywlClTRj7++GMZPHiwHD58WCpWrKges2HDBrn22mtVYIFyDoIw9LDgDc5bcA7wBohADcHGyZMn5aOPPpJly5ap76/LMTi2bdu2ySOPPKICv6SkJPUmiePVn19zzTXq2FC2w9chEMJrLOg8/Pvvv/LYY485zIDdddddMnHiRJk5c6Z07txZ/vOf/6jbEFjiuLVDhw6pgMj4sxs7dqy89NJLKjC477775NSpU/LJJ5+ogMb4+pz9njhz9uzZfLfhdeQtY+E48Dvy7LPPqnP14YcfSu/evWXjxo0qWHHnZ7F582ZV7sPvGLJfOP/79u2TGTNmqO9jhNeNoBPPt379evnqq68kPj5e3nrrLXU/fqYIHlu1aqV+txDI7t27V31PoiJhIqJCGTFihCnvf0pXXHGFum3ChAn5Hp+amprvtgceeMAUExNjSktLs942dOhQU+3ata2fHzhwQD1nxYoVTWfPnrXe/vvvv6vbZ8yYYb3t5ZdfzndM+DwyMtK0d+9e622bNm1St3/yySfW266//np1LMeOHbPetmfPHlN4eHi+57QHxx0bG+vw/oyMDFN8fLypRYsWpkuXLllvnzlzpnr+0aNHq8///fdf9fk777zj8LmmTZumHrNmzRqTOz788EP1dfh6R3CO8ZhBgwapz8+fP2+KiooyPfXUUzaPe/vtt00hISGmQ4cOqc8PHjxoCgsLM40dO9bmcVu2bFHn0Hi7s98Te/TP1d6lcePG1sctXLhQ3Va9enVTcnKy9faff/5Z3f7RRx+59bOAHj16mMqUKWN9nVpOTk6+47v33nttHjNw4ED1e6t98MEH6nGnTp1y6XUTFRbLWERFBH+t4i/mvPRf1IAMDcZ08Rcz0vwoExQEGYby5ctbP8fXAjI7BcFf9ShLafjLumzZstavRRYHTbnoV0GZTWvQoIHKPngDyk7IMiC7hDKZhtJekyZN5M8//7Sep8jISFWSQRbGHp11QPYlMzPT5WPAeQdktxzR9yHjBjhPOAfo8zHHjmYoFSHzU6tWLfU5skpoLEd2Az9bfUEpqWHDhrJw4UKXfk+c+b//+z+V4TJekIXKC5ko42tErw8ydrNmzXLrZ4HM1OLFi1V5UL9OzV5p88EHH7T5HL+jyGDpc6l/bijpetqET+QOBjtERaR69erqzTovpPAHDhyoehnwBooSjG5uPn/+fIHPm/fNRgc+jgICZ1+rv15/Ld740M+C4CYve7d5AmUfQI9GXniD1fcjCEDZAw3CKO2gBISSnXG8+oorrlClLpTb0GuCfh686aenpzs9Bh0A6KDH1YAIgSZ6XlasWKE+RxkH/Ta4XduzZ48KhhDY4GdrvOzYsUOdY1d+T5zBuUDgarygbygvHEPewAQ/R93z5OrPQgfD6C9yRUG/ozhfXbt2VSU+/GxRwkMQycCHigqDHaIiYszgGBs38Qa9adMm1auAfgf8Va57GVz5xz4sLMzu7cZsQ1F8rT88/vjjsnv3btX7gcwD+mAw0o9eEv3m/euvv6rgA83XaKpF9gHNthcvXnT4vHpZAPShOKLva9asmU3jMpqI8cYM+BgaGio333yz9TH4GeK40NycN/uCC5q9C/o9Ke4K+j3Da0amCFnEO++8U51rBEBXX311vkZ9Im9gsEPkQyjJIJ2PplA0x6JJE3+VG8tS/oQmUgQVaBbNy95tnqhdu7b6uGvXrnz34TZ9v4ay21NPPSV///23bN26VTIyMuS9996zeQzKSGiSRVlm8uTJKns2depUh8egp4DQ7O3ozRXrJwF+RhommvA5ppcQ1KCEhRKNseSH48WbOhp082ZfcMGx+gqyTEY4Lvwc9ZSfqz8LPYWG8+8tCBJ79eol77//vmzfvl39/NCsn7fMR+QNDHaI/PAXrzGTgjfv//3vfxIox4c3ZIynHz9+3Ho73iC9td4MRrQRVE2YMMGm3ITnR5kH/SKAHqa0tDSbr0UggbKS/jqURfJmpdq0aaM+OitlITuD9XXwhm5vdBq9KghIMdKeNzhBBgLnBhNGyNAZS1iAyTicR5TW8h4bPkew6ysI2IylOmTBTpw4Ye2/cvVngRIcSmfffPONmoTL+5rcZW+azJWfG5GnOHpO5EOXX365yuJgDZdHH31UlTuw8nIglZGwng6yKOipeOihh1Tm49NPP1X9GhhZdgWahV9//fV8t2O9GTTDomyHplyU9G677TbruDMyDk888YR6LMpX+Msfjb4oJWG0etq0aeqx6PGAb7/9VgWK6IFCIIQ3dqw8jV6ofv36OT1GjKqjHIZjQRkMvT8or2AsHWvkoNSF588Lz4uAC8ESghp8nRGOA6991KhRqjcGzd54/IEDB9TxY2wbX1sYCFrsraCMMpBxdB3nG1ksnGucN4yeo2fn/vvvV/djjNyVnwVgmQI812WXXaZeAzJXeH0IDF39vdBQwkUZC8EUskfoY8LPEesp4XsQeV2h57mISjhHo+fNmze3+/hly5aZOnfubCpVqpSpWrVqpmeeecY0Z84c9RwYGS5o9NzeKDZux9hvQaPnONa88D3wvYzmz59vatu2rRpVr1+/vumrr75SI9fR0dEFng88l6PxaDyX9tNPP6nvgXHuChUqmIYMGWI6evSo9f7Tp0+r423SpIkaZY+LizN16tRJjU9r69evN912222mWrVqqefBGPV1111nWrt2rckV2dnZpokTJ5q6du1qKlu2rHp9+Lm9+uqrposXLzr8OhwrXk/v3r0dPub//u//TN26dVPHjgteB17Prl27XPo9cXf03Pj7o0fPf/zxR9OoUaPUecHvW//+/fONjrvys9C2bt2qxsjLlSunzhXG3V966aV8x5d3pBznGLfjd1j/fg0YMED9/uN3DB/xc9y9e7fL54LIHSH4P++HUEQUbJChQC9M3j4QCszesCuvvFL1FmHcnKikY88OEeWD8XMjBDhYmwXbGxARFTfs2SGifDB9g72N8BFrrWCXbawF88wzz/j70IiI3MZgh4jywd5YP/74o1rAD4v7YcG6N954I98idURExQF7doiIiCiosWeHiIiIghqDHSIiIgpq7Nmx7GWDFVGx8Je9HXyJiIgo8KATB4uJYssWbEHiCIMdERXo1KxZ09+HQURERB44cuSIWoHbEQY7Iiqjo08WlpknIiKiwJecnKySFfp93BEGOxhJs5SuEOgw2CEiIipeCmpBYYMyERERBTUGO0RERBTUGOwQERFRUGPPDhER+U12drZkZmb6+zAoQEVEREhYWFihn4fBDhER+WV9FOy9du7cOX8fCgW4cuXKSZUqVQq1Dp5fg51x48bJb7/9Jjt37pRSpUrJ5ZdfLm+99ZY0btzY+piePXvKokWLbL7ugQcekAkTJlg/P3z4sDz00EOycOFCKV26tAwdOlQ9d3g4YzkiokCkA534+HiJiYnhgq5kNyBOTU2VpKQk9XnVqlXFU36NBhDEjBgxQjp06CBZWVny/PPPyzXXXCPbt2+X2NhY6+Puv/9+GTNmjPVz/IdhTIH2799fRX3Lly+XEydOyF133aVSX9ilmYiIAgv+3daBTsWKFf19OBTAkAgBBDz4ffG0pOXXYGf27Nk2n0+aNEm9mHXr1kmPHj1sghsEM/b8/fffKjiaN2+eJCQkSJs2beS1116TZ599Vl555RWJjIws8tdBRESu0z06xj9ciRzRvyf4vfE02Amoaazz58+rjxUqVLC5ffLkyVKpUiVp0aKFjBo1SqW1tBUrVkjLli1VoKP16dNHraq4bds2u98nPT1d3W+8EBGRb7F0Rb76PQkPpM04H3/8cenatasKarTbb79dateurTb52rx5s8rY7Nq1S/X66LqvMdAB/Tnuswf9PK+++mqRvh4iIiIKDAGT2UHvztatW2Xq1Kk2tw8fPlxlapC9GTJkiHz33Xcybdo02bdvn8ffC9khZJH0BXtiERER+UOdOnXkww8/dPnx//zzj8p2cJKtmAU7I0eOlJkzZ6ppKme7lkKnTp3Ux71796qP6OU5efKkzWP05476fKKioqz7YHE/LCIicgUCDGcX9Il6Ys2aNeoPe1dhchnDOHFxcVKU/gmioCrc32NljzzyiMrU4KTWrVu3wK/ZuHGjzQhaly5dZOzYsdZObZg7d64KYJo1aybFwaWMbCkVWfhFk4iIqOggwNB++uknGT16tGqr0LD0ifH9DVNnriyBUrlyZbeOA4M3jv6YpwDM7KB09cMPP8iUKVPU9uzoscHl0qVL6n6UqjBZhemsgwcPyh9//KHGyjGp1apVK/UYjKojqLnzzjtl06ZNMmfOHHnxxRfVcyODE+jG/bVDWo/5W3YmskmaiCiQIcDQF2RVkPXQn2O9OLyP/fXXX9KuXTv1/rN06VL1PjZgwADVS4pgCEutYHrYWRkLz/vVV1/JwIED1SRSw4YN1fufo4wLJpmx8B7e/5o2baq+z7XXXmsTnGVlZcmjjz6qHodxf/S/Yk26G2+80ePz8e+//6r35PLly6vj7Nu3r+zZs8d6/6FDh+T6669X92M5mebNm8usWbOsX4vWFAR6GC/Ha5w4caIEZbAzfvx41TODhQORqdEXRMw6esUvBQKaJk2ayFNPPSWDBw+WGTNmWJ8DY2gogeEjsjx33HGHOvnGdXkC2bqD/0pGVo5sO8Zgh4hK+AJyGVk+v+D7etNzzz0nb775puzYsUP9UX7x4kXp16+fzJ8/XzZs2KCCEAQAWAzXGQzR3HLLLWowB1+PwODs2bMOH48p5XfffVe+//57Wbx4sXr+p59+2nr/W2+9pSabEVAsW7ZMTSFPnz69UK/17rvvlrVr16pADJPROJc4Vr20AJIOmH7G8WzZskUdg85+vfTSS2rZGASHOFeIBzB1HbRlLGdq1qyZb/VkezCtpaPF4iY1I1t9TM/K8fehEBH5zaXMbGk2eo7Pv+/2MX0kJtJ7b4X4Q/vqq6+2fo6lVFq3bm39HNUKtG4gQEC/qrNA4rbbblPXsUDuxx9/LKtXr1bBkj0IMLCzQP369dXneG7jH/2ffPKJGs5Btgg+/fTTQr1vIoOD14DACT1EgGAK79sIom6++WYVcCFBgQEjqFevnvXrcV/btm2lffv21uxW0Dcol/T/wCE9y/yRiIiKL/3mrSGzgwwLyksoISGzgUxGQZkd3aoBKAGhD1Vvm2APykg60AFUSfTjz58/rwZ3OnbsaL0f1RCU2zyF14B+JD00BCiPYbsn3Acom73++utqSZmXX35ZZak0bPGE6WssBPzMM8+oHRCKUsCss1NSpaRnqY9pmczsEFHJVSoiTGVZ/PF9vcm41REg0MHQDEpMDRo0UP0pN910k2RkZDh9Hmx5ZIQeHaxH587jvV2ic9d9992nlo75888/1W4HWOPuvffeU4NJ6O9BTw+ySzg/vXr1UmUvnKeiwMxOAExiATM7RFSS4c0Z5SRfX4p6FWeUeVCSQvkI5Rw0M2Pgxpfi4uJUgzRG3DVMiq1fv97j50SmCk3Pq1atst525swZNZ1mnIRGWevBBx9UCwGj7/bLL7+03ofmZDRJY1AJDdpffPGFFBVmdvzdkGctYzGzQ0QUbDBlhDd6NCUjsEJjrrMMTVF55JFHVGYF2SUM/KCHBxNRrgR7aC7GpJmGr0EfEqbMsFH3559/ru5Hc3b16tXV7YBdEZDBadSokfpeWEsPQRJgbB9lNExooYkZg0b6vqLAYMePMrJzJDvHnGZMZxmLiCjovP/++3LvvfeqJl5MG2Hk2x/7MT777LNqaRdMK6NfR+9O4MrGmsaNuQFfg6wOJrsee+wxue6661RZDo9DWUqX1JA9Qmnq6NGjqucIzdUffPCBddoaDdPIcqG0171793w7KHhTiMnfRb0AgF88pPnQxOXL1ZTPpWZImzFz1fXbO9WSNwaaO9aJiIJZWlqaHDhwQC0kGx0d7e/DKZFycnJUJgXj7ZgQK66/L66+fzOz40cpln4dYGaHiIiKyqFDh1ST8BVXXKHKRhg9RwCBzbZLAjYo+9GlDPMkFrBBmYiIikpoaKhaaRkrOGMUHH04WLS3KPtkAgkzOwGwoCBw9JyIiIpKzZo11WRYScXMToAEO8zsEBERFQ0GO36EfVk0jp4TUUnD+Rjy1e8Jg51AyexY1tshIgp2ejQZm1cSFUT/nuRdJdod7NkJmDIWMztEVDJgnRbsE6X3bsK+TkW9kjEV04V3U1PV7wl+X1xZE8gRBjsBsFUEMNghopIE2yaAs80tiQCBjv598RSDHT9iGYuISipkcrAzd3x8vGRmZvr7cChAoXRVmIyOxmAnQBqU05jZIaISCG9k3ngzI3KGDcp+xMwOERFR0WOw40dsUCYiIip6DHYCZLuIrByTZGUz4CEiIvI2BjsBktkBZneIiIi8j8GOHzHYISIiKnoMdgJkGgu4PxYREZH3MdgJoMwOdz4nIiLyPgY7fnQpz7g5MztERETex2DHj1LS8wQ7zOwQERF5HYOdABg9Dw81b4CXxoUFiYiIvI7Bjj93c7UEN+ViItVHTmMRERF5H4MdP0FgYzKZr5ePibDeRkRERN7FYCcAJrHKWzM7LGMRERF5G4MdP0lJN/frRIaHSqlI846/HD0nIiLyPgY7fh47j40Mk+gI84+BmR0iIiLvY7Dj5zJWTGS4RIWbMzscPSciIvI+Bjt+3ioCJayocPOPIY2ZHSIiIq9jsOMnl6yZnTCJ0mUsZnaIiIi8jsGOn6QYgp1oXcbi6DkREZHXMdjx8+rJqmeHDcpERERFhsGOnxuUzT07HD0nIiIqKgx2/D2NFcHRcyIioqLEYMfP01iqQdmDnp3vVx6SX9YeKbLjIyIiChbh/j4AKemZnSiss6OnsVzL7CSnZcro37eq3dIHXVZDwiy7phMREVF+zOz4e/Q8wjB67mJmJy0jW20impltksxs9vkQERE5w2AnABqUraPnLjYoZxgCHON1IiIiyo/BTiBsFxHh3grKWdkm6/VMrs1DRETkFIMdPzcox0YZGpRdzOwYS1coZREREZFjDHb8XcbyYPTcWLpizw4REZFzDHb8vjeWYddzF0tSxmwOe3aIiIicY7DjJ6mZdnY9d3H0PIuZHSIiIpcx2PGT1HTDruduZnZsylhZ7NkhIiJyhsGOn3t2YiPDDT07LGMRERF5G4MdP8jJMcmlzPwbgWbnuLZIIMtYRERErmOw4wfG9XRUGcuS2XE1u2MMcIxr7hAREVF+DHb8WMLSo+e6QdnV/bEyjIsKMrNDRETkFIMdPzYnI9AJDQ2RkJAQidSbgWa5V8Zizw4REZFzDHb8OHaOEpbmzvi57QrKDHaIiIicYbDj501ANXfGz1nGIiIich2DHb+unpwb7Lgzfm7c/JPr7BARETnHYMevmZ1wj8pYWTns2SEiInIVgx1/7njuYRnLuKggy1hERETOMdjxY2bHbhnLldFzYxmLwQ4REZFTDHYCpozlembHWMYyZnmIiIgoPwY7fnDJUsaKiTCUsSLcGT037I3l4n5aREREJRWDHT9I0WWsqPzr7Lg0es4yFhERkcsY7ATM6LmnZSwGO0RERAEb7IwbN046dOggZcqUkfj4eLnxxhtl165dNo9JS0uTESNGSMWKFaV06dIyePBgOXnypM1jDh8+LP3795eYmBj1PP/9738lK8tcKgrkaawYD0fPjWvrsGeHiIgogIOdRYsWqUBm5cqVMnfuXMnMzJRrrrlGUlJSrI954oknZMaMGfLLL7+oxx8/flwGDRpkvT87O1sFOhkZGbJ8+XL59ttvZdKkSTJ69GgJ+AblCE9Hz5nZISIiclVuasEPZs+ebfM5ghRkZtatWyc9evSQ8+fPy9dffy1TpkyRq666Sj1m4sSJ0rRpUxUgde7cWf7++2/Zvn27zJs3TxISEqRNmzby2muvybPPPiuvvPKKREZGSvFaQdmVXc8Z7BARERXLnh0EN1ChQgX1EUEPsj29e/e2PqZJkyZSq1YtWbFihfocH1u2bKkCHa1Pnz6SnJws27Zts/t90tPT1f3Giy+l6DJWlJ3R80xXdj1nGYuIiKjYBTs5OTny+OOPS9euXaVFixbqtsTERJWZKVeunM1jEdjgPv0YY6Cj79f3OeoViouLs15q1qwpfsns2JSxXM/sGLM53C6CiIiomAQ76N3ZunWrTJ06tci/16hRo1QWSV+OHDki/l5BWa+z40pmx6aMxXV2iIiIArdnRxs5cqTMnDlTFi9eLDVq1LDeXqVKFdV4fO7cOZvsDqaxcJ9+zOrVq22eT09r6cfkFRUVpS7+X0HZw9Fz7o1FRERUPDI7JpNJBTrTpk2TBQsWSN26dW3ub9eunURERMj8+fOtt2E0HaPmXbp0UZ/j45YtWyQpKcn6GEx2lS1bVpo1ayYBvRGoTc+OOysoc7sIIiKiYpHZQekKk1a///67WmtH99igj6ZUqVLq47Bhw+TJJ59UTcsIYB555BEV4GASCzCqjqDmzjvvlLfffls9x4svvqie25/ZG1+NnrNnh4iIKICDnfHjx6uPPXv2tLkd4+V33323uv7BBx9IaGioWkwQU1SYtPrf//5nfWxYWJgqgT300EMqCIqNjZWhQ4fKmDFjJBBl55isAY2no+fGbA7LWERERAEc7KCMVZDo6Gj57LPP1MWR2rVry6xZs6Q4uGQoU9muoGwOfNJcaFDmooJERETFcBqrpND9OiEhudmcwoyeG7eOICIiovwY7PhYanruGjshiHjyjp671LPDMhYREZGrGOz4bezctoLozgrKbFAmIiJyHYMdH7uUmZWvORl0SSvN3TIWgx0iIiKnGOz4mL3Vk93P7JjsLjBIRERE+THYCZRgxzB6XtCUGstYRERErmOw46dpLOPYuTGzk2MqeFVklrGIiIhcx2AnAPbFMo6eFzR+jkUJERBp3C6CiIjIOQY7PnbJYc+OMdhxnK3Jm8lB8IMLERER2cdgJ0B6drDmTu7Cgq4HO45uIyIiIjMGOz6W4qBnx9Wdz+2VrRjsEBEROcZgJ0DKWBAVUfD4uQ5sDIsvs2+HiIjICQY7AdKg7OrO5zrYiQwLlfBQc8TDzA4REZFjDHb8ldmxZHGMXNn5XGdxEOxEhJl/fBku7KdFRERUUjHY8dc6O1GOe3ZcyexEhIdKeBgzO0RERAXJ/45LRSrFWc+OG9NYKGGFWGJV9uwQERE5xmAngBqUo3WDstNgxxzYoIQVGmK+zswOERGRYwx2/FTGKhXh6ei5pUE5PFSycszXGewQERE5xmAnkEbP9c7nrpaxQljGIiIiKgiDHT/17MRGORk9d2FRQZSxwiy7ozOzQ0RE5BiDHT9ldkrZXUHZhcxOVu40Vo5lT6wMBjtEREQOMdjxoazsHGtgYnedHRcyO7pPJzIsRLJDbAMgIiIiyo/Bjg+lGoKYUh6OnmdYyljhocZpLPbsEBEROcJgxw8lrLDQ3B3O7Y2eO53GMpSxTOzZISIiKhCDHR9KSbesnhwRJiHGnTw9WFQQZawck/k52LNDRETkGIOdANkE1OUG5ZzcMpZJmNkhIiIqCIMdH7qU6XiNHZd3PbdXxmKDMhERkUMMdvyS2bF/2l3b9dwS7GATUEsZiw3KREREjjHY8aFUS89OrKMylguZnSxLGSvCUMZizw4REZFjDHYCqmdHr7PjZPTcWsYKEZM1s8Ngh4iIyBEGO37YBDTWURlLj54769mxlrHQs2N7GxEREeXHYMcPmZ2YQmR2rGWssNx1erLYs0NEROQQgx0/bAIaY2cTUFdHz61lLDQo69uY2SEiInKIwY4PXbKUsWIclLFcGj03lLHy3kZERET5MdjxR2angEUFXRs9NwQ7WSxjEREROcJgxw97YxXYs+Ns9NzSn4MyFv4HzOwQERE5xmDHH3tjOZzGyt0bC6sj29s/K8OQ2dH3smeHiIjIsfxbb5Mft4sw346RckcBjLGMhS0jjLcRERFRfgx2AimzYwlenE1kGctYum+H20UQERE5xmAngNbZiURpylKbcrTWjrGMhccDMztERESOMdjxQ7AT62CdHfToFNSkbFPGsgQ7eu0dIiIiyo/Bjj/2xopw3Bde0Pi5sYwVbllYkJkdIiIixziN5Y+9sRxkdsCdzE6opebFnh0iIiLHGOz4SE6OyTqN5WjX87zj5/ZkWDM7xmCHmR0iIiJHGOz4CHYy17uUxzqYxoJoaxnLlcyO7W1ERESUH4MdH/frQCnLejqeZHayrMFOiIRaoh2WsYiIiBxjsOMjqem6OTnMGqQ43fncQYOyDmyQ2QmzBjvM7BARETnCYMdHUjP1goKOszqu7HxuXGeHwQ4REVHBGOz4SIolsxPjZBLLlcyOsYylgx2us0NEROQYgx1f73juZI0d10bP7ZWx2LNDRETkCIMdH0mxrLFTcGanoNFzS2YnPFTCWcYiIiIqEFdQ9nVmp8CeHeej59YyVmjuRqBZOSa1jg8RERHlx2DH15kdJ2vsFJTZyUZQY4lpzHtj5U51ZeYwu0NERGQPg50Ay+xEWTI79oIdY7kKZSyd2THfx8wOERGRPQx2fD2NVUBmJ9qS2bFXxtL9OoCsjk2ww4ksIiIiuxjsBNg6O9bMjp3Rc73jOUSEmqexuGUEERGRcwx2fLyCcmxBwY6T0XMd0KggxxLl6OyOMetDREREuRjs+HhvrFKFaFDWiwcaG5MjLcEOe3aIiIjsY7DjI5csZazYgtbZcTJ6jhFzXcIyNiqr+5jZISIisovBjo8blJ3teF5QZkeXsXSAY8zysIxFRERkH4MdH4+ex0YVVMYKc6uMpXt2WMYiIiKyj8GOjxcVLOXirufOyljhhjJWbs8OMztEREQBF+wsXrxYrr/+eqlWrZqEhITI9OnTbe6/++671e3Gy7XXXmvzmLNnz8qQIUOkbNmyUq5cORk2bJhcvHhRAjazU2CDcsGLCkbalLEswQ7X2SEiIgq8YCclJUVat24tn332mcPHILg5ceKE9fLjjz/a3I9AZ9u2bTJ37lyZOXOmCqCGDx8ugbtdREENyk5Gz+2VscLZs0NERBSwu5737dtXXZyJioqSKlWq2L1vx44dMnv2bFmzZo20b99e3fbJJ59Iv3795N1331UZo0AbPS8w2LGuoGynZ0c3KBtWTmbPDhERUTHv2fnnn38kPj5eGjduLA899JCcOXPGet+KFStU6UoHOtC7d28JDQ2VVatWOXzO9PR0SU5OtrkUJZPJZAh2nMeX+n5d9rK3gnK43WCHmR0iIqJiF+yghPXdd9/J/Pnz5a233pJFixapTFB2tjkQSExMVIGQUXh4uFSoUEHd58i4ceMkLi7OeqlZs2aRvg5kZLBjOcQUsM6OzvykZmSpIMluz47dRQUZ7BAREQVcGasgt956q/V6y5YtpVWrVlK/fn2V7enVq5fHzztq1Ch58sknrZ8js1OUAY/eKgJiClhnR09rITZCk3K04fH2y1iWnh02KBMRERW/zE5e9erVk0qVKsnevXvV5+jlSUpKsnlMVlaWmtBy1Oej+4AwvWW8FKVUyxg5pqiMJSh7jMFQ3lKWvTKWvs6eHSIioiAIdo4ePap6dqpWrao+79Kli5w7d07WrVtnfcyCBQskJydHOnXqJIEiNd21SSwdvOjSlA6SNJaxiIiIilkZC+vh6CwNHDhwQDZu3Kh6bnB59dVXZfDgwSpLs2/fPnnmmWekQYMG0qdPH/X4pk2bqr6e+++/XyZMmCCZmZkycuRIVf4KxEms2AKak42lrIxLOXLJMq6eb7sIO2UsBjtEREQBmNlZu3attG3bVl0AfTS4Pnr0aAkLC5PNmzfLDTfcII0aNVKLBbZr106WLFmiylDa5MmTpUmTJqqHByPn3bp1ky+++EKK4+rJ+ZuU82Z2nE1jsYxFREQUcJmdnj175ps4MpozZ06Bz4EM0JQpUySQ5a6e7FqwU8phsGNvUUGWsYiIiIKmZ6e4SrEELe5mdvI2KOf27HBvLCIiIlcx2PEB3XsT62LPTkxEeAFlLOOu59wugoiIyBkGOz6Qku5eZie3jOVKg7LeCJQ9O0RERPYw2PGBS5YR8lhXMzu6jOVw9JzbRRAREbmKwY4PpFjW2XE/s2O/jGXM7GChQvN9DHaIiIjsYbDjy3V2CtgXS4u1ZIAcTWOxZ4eIiMh1DHZ8QPfeFLTjef5pLDd6drjODhERkfeCnSNHjqitG7TVq1fL448/HnCL+QUKnaFxZbsIV8pYdnt2uBEoERGR94Kd22+/XRYuXKiuJyYmytVXX60CnhdeeEHGjBnjyVMGNXeDnYLW2bFXxmLPDhERkReDna1bt0rHjh3V9Z9//llatGghy5cvV1s3TJo0yZOnDGrulrFKFdCzY6+MxZ4dIiIiLwY72HBT7081b948tX8VYI+qEydOePKUQc3tzE5EmM2eWi6VsRjsEBEReS/Yad68udplHJtyzp07V+08DsePH5eKFSt68pQlJNgJL4IyFhuUiYiIvB7svPXWW/L555+rjTxvu+02ad26tbr9jz/+sJa3KFeqZZ2dwjco5y9jRYabA58sZnaIiIi8t+s5gpzTp09LcnKylC9f3nr78OHDJSYmxpOnDGqpme6ts6MzQPlXUDY56dlhZoeIiMhrmZ1Lly5Jenq6NdA5dOiQfPjhh7Jr1y6Jj4/35CmDWqp1byz3yliO9sbS2Rxgzw4REVERBDsDBgyQ7777Tl0/d+6cdOrUSd577z258cYbZfz48Z48ZdBCEKInpWK9tM5OeCgblImIiIo02Fm/fr10795dXf/1118lISFBZXcQAH388ceePGXQMgYsru6NVVCDsk3PDhcVJCIicsqjYCc1NVXKlCmjrv/9998yaNAgCQ0Nlc6dO6ugh3LpgCU8NMRmZNyZmAhzuSsrxyQZhiDGbhnLcp09O0RERF4Mdho0aCDTp09X20bMmTNHrrnmGnV7UlKSlC1b1pOnDFp6rRxkdUJCcoMUZ4wZIGN2J4tlLCIiIt8EO6NHj5ann35a6tSpo0bNu3TpYs3ytG3b1pOnDFo6WIl1sTkZIsNDVSYIUjNzm5QznJWxGOwQERF5b/T8pptukm7duqnVkvUaO9CrVy8ZOHCgJ08ZtFLcXGPHmN25kJZl0/PDaSwiIiIfBTtQpUoVddG7n9eoUYMLCjpZYyfGxTV2tBhLsFNwGUtvBGoSk8nkcqmMiIiopPCojJWTk6N2N4+Li5PatWurS7ly5eS1115T91H+NXZ007Gr9MKCxsyOtYwVnvtjCzeUtLhlBBERkZcyOy+88IJ8/fXX8uabb0rXrl3VbUuXLpVXXnlF0tLSZOzYsZ48bXDveO5mZqeUZTNQ/fXI2uSOnudmb4wTXrgf/T5ERERUyGDn22+/la+++sq62zm0atVKqlevLg8//DCDnULseO5orZ3sHJSpxM6u57mBD/t2iIiI8vMoDXD27Flp0qRJvttxG+4jz3c8d7SKMtbcsVe6CgsNEd2mo8tcREREVMhgBxNYn376ab7bcRsyPGSnjOVmZidW9+xYGpyNgYwxm4OGZD2RpRuYiYiIqJBlrLffflv69+8v8+bNs66xs2LFCrXI4KxZszx5yqDlaWYnt4yVlW87iAjDNJYua2GlZZaxiIiIvJTZueKKK2T37t1qTR1sBIoLtozYtm2bfP/99548ZdDyNLPjqIyFslWoZcHB/OPnDHaIiIi8ts5OtWrV8jUib9q0SU1pffHFF54+bdDxVoOy3iPLWMLSdBkrI4tlLCIiorw4p1zEUtI9bVC2XWfH3o7nGldRJiIicozBThG7ZNnbKtaDFZTtlbHsBTt6bR0GO0RERPkx2PFRZkcvEuh2GcsSLDkvY5lv4+g5ERFRfm7VVtCE7AwalcnBrudRbpaxLMGRDpZcK2OxZ4eIiCgvt96BsRdWQfffdddd7jxl0EuxTGPp6SpX6R4fHSzpQMa4enK+YMcwnk5EREQeBDsTJ0505+FkzOx4uM5OqqWMlWXJ7IQ7KWOxZ4eIiCg/9uz4KLNT2HV2rDueO8nssGeHiIgoPwY7RQibd6Zl5nhlnR1dxmLPDhERkXsY7BShS5Z9rQqzXYR19Dy74EUFWcYiIiLKj8GOD7aKwK7k0RGhHi0qeMmFMlZkeIhNQERERES5GOwUoVS9enJEmNqd3B34Gh3kIIhxpYyVwTIWERFRPgx2fLEvlptr7OQdVU/NzGYZi4iIyEMMdgJwx3OICg8Vvbk5SlkuLSrIdXaIiIjyYbDjkx3P3c/soOylvw7Po0tUdnt2uM4OERGRQwx2AjSzY7vWTpY1kLG/qCB7doiIiBxhsOOTzI5nwY5xrR3ds2N3uwjuek5EROQQg50ilFLIYEdvBlpQGYsNykRERI4x2ClClyxlrFgPenbU11mmuFILaFBmzw4REZFjDHaKUIplnR13dzzPV8bKzHJp9Dwjiz07REREeTHY8cF2ETpDU5gylrNFBcNZxiIiInKIwU4RSknPsglaCtOg7HS7CJaxiIiIHGKwU4T0vlaxUZ6Onuf27GS5MHrOYIeIiCg/BjtFKMXSoKyDFncZdz7XZSy7o+dcZ4eIiMghBjs+WGcnttDr7GQZylghDtfZ4a7nRERE+THYCeBFBXNXUM627nulm5GN2LNDRETkGIOdAN0bS32dYRorK4dlLCIiIk949i5MPtkbK3cj0CxrsBMR7qRBmbueExER5cNgpwiNG9RSzqVmSv3KpQtdxtK4XQQREZF7GOwUocvrVyrU1+euoJxtDWjCQ+307FiyPQx2iIiI8mPPTgCzaVDWu547K2OxZ4eIiCgfZnYCmO7ZweKE4aEhBZax9Hg6ERER5WJmJ4DlLiqY26Bsr4zFnh0iIiLHGOwEMNuNQJ2VsSw9O5zGIiIiCqxgZ/HixXL99ddLtWrVJCQkRKZPn25zv8lkktGjR0vVqlWlVKlS0rt3b9mzZ4/NY86ePStDhgyRsmXLSrly5WTYsGFy8eJFCabMTnpWjqRnOt4IlD07REREARrspKSkSOvWreWzzz6ze//bb78tH3/8sUyYMEFWrVolsbGx0qdPH0lLS7M+BoHOtm3bZO7cuTJz5kwVQA0fPlyCgXExwuS0zALLWOjZQYBIREREAdKg3LdvX3WxB2/aH374obz44osyYMAAddt3330nCQkJKgN06623yo4dO2T27NmyZs0aad++vXrMJ598Iv369ZN3331XZYyKs+iIUAkJwbnIXWvHXhnLuKoyenvs7Z9FRERUUgVsz86BAwckMTFRla60uLg46dSpk6xYsUJ9jo8oXelAB/D40NBQlQlyJD09XZKTk20ugQilPd23o9ktYxkCoCyWsoiIiIpHsINAB5DJMcLn+j58jI+Pt7k/PDxcKlSoYH2MPePGjVOBk77UrFlTAlXerSac9ewAx8+JiIiKSbBTlEaNGiXnz5+3Xo4cOSKBKu8mouF2SlR6DR7g+DkREVExCXaqVKmiPp48edLmdnyu78PHpKQkm/uzsrLUhJZ+jD1RUVFqest4KS6ZHXu7nqPcpW9nsENERFRMgp26deuqgGX+/PnW29Bbg16cLl26qM/x8dy5c7Ju3TrrYxYsWCA5OTmqtyeYtoxwVsayXWuHPTtEREQBM42F9XD27t1r05S8ceNG1XNTq1Ytefzxx+X111+Xhg0bquDnpZdeUhNWN954o3p806ZN5dprr5X7779fjadnZmbKyJEj1aRWcZ/EcpTZsVfGgojwUDTssGeHiIgokIKdtWvXypVXXmn9/Mknn1Qfhw4dKpMmTZJnnnlGrcWDdXOQwenWrZsaNY+OjrZ+zeTJk1WA06tXLzWFNXjwYLU2T7AoFWH7I4qws86Oup1lLCIiosALdnr27Ol0ETz0oowZM0ZdHEEWaMqUKRKsjJkdNCKHGpqRjdizQ0REVMx6dshOsONksUBrzw6DHSIiIhsMdopRg7Kj5mTjfRlsUCYiIrLBYKcYZXbsjZ1r4SxjERER2cVgJ8AZFxV0ltmJZBmLiIjILgY7Ac64N5bznh1mdoiIiOxhsBMkZSxrzw43AiUiIrLBYCdYGpSxqKDa9ZyZHSIiIiMGO8WoZ8dZGYs9O0RERPYx2ClGZawIN8tYMzcflx9WHnK6cCMREVGw8+sKyuReGcuVnp3MLHNmZ862RBk5ZYO6XrtijHRvWLnIj5WIiCgQMbMTNCso505j7U26IE/+tNF638fz9zC7Q0REJRaDnQAXE+HiOjvh5kDobEqGDP9unaRkZEubmuVUNmjNwX9l5f6zLn2/c6kZctsXK+X7lYe8cPRERET+x2AnyLaL+GbZAdl/OkWqxUXLV0Pby3861LRmd1wxa0uirNh/Rt6ZvVMyLCUxIiKi4ozBTnFaZ8eSvXFexjJJZHioTLiznVQqHSUP9qyvNglFALPmYMHZnU1HzqmPyWlZsnzfaa+8BiIiIn9isFOcVlAOLTizA+MGtpRWNcqp69XLlZKb2rme3dloCXZg1pYTHh83ERFRoGCwE+BCQ0OsAY+zMlbTqmXUx/u715XB7WrY3Pdwz/oSFhoiS/aclvWH/3X4HBfTs2R30gXr539vP8l1e4iIqNhjsFOMSlnOylgD2lSX9S9dLS/0b5bvvpoVYmRQ2+rq+idOsjtbjp4XDG1VKRstlUpHyrnUTFm5/4xXXgMREZG/MNgpRk3KzspYUCE20uF9I65sIKEhIgt3nVJBjT2bjppLWG1rlZNrmlexNiwTEREVZwx2ilFmx1kZqyB1KsXKjW3M2Z0vl+y3+5iNh83BDkbW+7Woal2ckPttERFRccZgpxgoZdkfK8JJGcsVd3SprT4u2Jkk6VnZDjM7CHY61asg5WMi1Lo9qw+4tkYPERFRIGKwUwzE6AblAspYBWlTo5xULhOlGpFX5Vlk8GRympw4n6ZKXS2qx6ks0jXNLKWsrZzKIiKi4ovBTgkpY+nJrt5N49X1udtP2h05b5RQRmKjzJmkfq3MpazZW09Kdg63myAiouKJwU4xalAubBkLrm6WoD7O23HSZr8sHeyghKVdXr+ixJWKkNMX011akJCIiCgQMdgpBhCAoLzUrGrZQj/X5fUrqXV7ULLadjw538rJxmAHmSQdHP3lpQUGz6dmclNSIiLyKQY7xcB93evJppevkZ6NzSWowoiOCJMejSpZFw0ElKg2W8bRWxuCHejX0ty389fWRMkpZClr+oZj0nrM3/LL2qOFeh4iIiJ3MNgpJspER3jtua62NB7PswQ7+09dVE3L6A1Cz45R1waVpExUuCRdSJebJiyXj+btkXWH/vVoHH36xmPq4x+bjnvldRAREbmCwU4JdFWTeFUW234iWY7+myobLCUsTGFhWwmjqPAw68j6+sPn5IN5u2Xw+OXS9rW58uVi++v12IPgaI1lhH3DYc+CJSIiIk8w2CmBsNJy+9oVrNkd3a/TNk8JS3v22iay5Jkr5Y2BLVVZC03LF9Ky5I2/dsjB0ykufU/0B6VkmNf2wcedibl7cBERERUlBjslVO5UVpLdSSx7+2vd3qmW/G9IO7UHV8/GldU+Wl84WI05r1UHbPfYWsvpLiIi8hEGOyVUb0uwg40+dZYlb3OyIyh1PXRFfXX913VH5dSF9AK/Ri9iiEUNYe0hx7uvExEReRODnRKqbqVYaRBfWrJyTGoaK75MlFSNi3b56zvWraAyQRlZOTJp+QGnj8Xz6y0nhnevpz6iyZmIiMgXGOyUYLqUpbM6ISGuL1qIxz5oye58v+KQmuZyZMeJZLmQnqWmum7tWFNlhrDOz7Fzlwr5CoiIiArGYKcE6900N9hx1q/jLFiqVylWktOyZOrqww4fh1IZtK9TXo3Qt6hmXhyRfTtEROQLDHZKMExfoXwF7WqXd/vrkaEZ3sNclvp66QFV0rJnlaWE1bleRcv3Mk+CrT3IUhYRERU9BjslGDYGnXBnOxk7sIV0qmsOQNx1Y9vqqukYZSl7iwXmGPp1OlmCHWR4gE3KRETkCwx2SrjLapWXIZ1qu9Wvk3f7iXu71lXXv1i8L9+WEpj0On8pU2Ijw6zlq/aWLNKuxGS5kJZZ6NdARETkDIMdKjSsv1M6Klx2n7woc7Yl2l1fp32dChIeZv51iy8bLbUqxAjiog2HzWv8aNgkFL08WKyQG4YSEZE3hHvlWahEw4rKQy+vLZ8t3CcvTN8ql9UuLwllo22akzvVsy2TIbtz+GyqCmx6NKpsvX3Cov3y1uyd6nr5mAjVON22VnmVgUJfUanIMJ++NiIiKv4Y7JBXPHJVQ1mw85QaM3/ip43y/bBOgsKYtV+nrrlfR2tXp7z8tuGYTd/OrsQL8sHc3ep6RFiI/JuaKQt3nVIXfRuCny71Kkrn+hWloyFbRERE5AjfKcgr0Lvz6e1tpVREmCzfd0YmLNone5IuqoAFt7WqEWfzeL03F7aqwKaguPz3102SkZ0jvZrEy7ZXr5XfR3SVV65vJje0ribV4qIlM9skaw7+Kx8v2Cu3f7lKnv5lk59eLRERFSfM7JDX1K9cWl4d0Fye+XWzvD93t+xNumidvorIk4FpGF9aykaHqzV6dpy4IIv3nJLNR8+r294Y1FIiw0PVQoe43N3V3MuDsteKfWdkyZ7T8ueWEzJn20k17o7HEhEROcJ3CfKqm9vVUJkYbBExbcMxdZu9sXaMveu1faasPiQfzjOXr165obm138cI02K1K8bKrR1rySe3tZVKpSPlUma2bDjM8XUiInKOwQ55FYISrNuDaStNr6+TFya04MfVR1SJqnfTeBnYtnqB3wOB0uX1K6nry/ae9tqxExFRcGKwQ16HLSGQfUFDcYXYyHz9OppebwdQvho7sKXL6/10a2gOdpYw2CEiogKwZ4eKBHpt/nqsh0SGhUpUeJjDx6DfBn03jspXjnRtYA52Nh05J8lpmVI2OsJrx05ERMGFwQ4VmQbxpQuc4Prs9svk1IV0l8pXRtXLlVKbkO4/nSIr952Ra5pX8egYl+87rY4D6/gQEVFwYhmL/Ao7p2MFZk+2q9DZnaUelrKOnE2VO79eLbd/uVLOpWZ49BxERBT4GOxQsaX7djwNdmZsPq6mxtIyc2SGnU1MiYgoODDYoWKrc72KEhoisv9Uihw/d8ntr5+x6YT1+q/rjkpJk5qRJa/8sU2Ws8mbiIIcgx0q1ntytapRzqMRdCx4iK0twkND1GXT0fOy5+QFu49FT9ExD4KpQPfDykMyaflBee3PHf4+FCKiIsVgh4q17h6WsmZuPm79+p6N49X1X9fnz+6cv5Qp/T5eIle/v0j1+AST39abF33cffKCXMrI9vfhEBEVGQY7VKzpJmVkdrClhCvwON2jc12ranJTO/Mk2PQNx1QPj9En8/eozE5qRrZ8OG+PBIvtx5NlZ6I5k4XXvP3EeX8fEhFRkWGwQ8Va21rl1Eajpy9myC4HZai88Ca/71SKWuPn6uYJclWTBCkfEyEnk9NlyR7zDuuw/9RFVebRpm046rDUVdzgtRhtOsJgh4iCF4MdKtawYGFHy95bS/fklrIW7Dwp1364WJ75dZPk5MnW6BJWz0aV1WKECHqwnxf8n6W0A2/M2ilZOSa5snFl6dM8QfA07/1t3sOrOEMm5/eN5nPQ2rK69eaj5/x8VERERYfBDgVV307ShTQZMWW93Dtprcrg/Lz2qHy6cK9NCWvmZvMU1nWWAAdualdTfZyzLVH16aAsNm/HSQkLDZEX+jeTp69pLFgKaPa2RLVqc3GG15Z0IV1ls0Ze1VDdtvkYMztEFLwY7FDQ9O2s2HdGer23SP7cfEIFKViwED6Yt1sW7kpS17ccOy+HzqSq0hc2HtVaVC8rjRPKqK0r/th0XF6buV3dfmfn2mol6IYJZayrPL/79y4pzn6zNGKjX0nvPI/xfWy7QUQUjBjsULGHIKVS6UhJz8qRC2lZauPRP0Z2lS/vai9DOtUS9C0/9uMGOXwm1ZrVuappvMRE5u6WghWcB1salcfN2qGyQhhtf7y3OfMBT/RupDY3XbLntNpmojhKSc+SOdtOquuDLquuNmqtUb6U+nzrUWZ3iCg4MdihYi80NETu6FxbvXGPvq6ZTHu4qzSvZu5FGX19M2lTs5wkp2XJAz+sk5mWKazrW+WWsLQb21RXGSFMXgECnXIxkdb7a1aIkds71lLX3569y+XpL3/J26sEs7cmyqXMbKlbKVadF2htWauIpSwiClYMdigoPN67kax7sbfc262uCliMDczj77hMZX6wiODx82lSOipcejaunO854stGSw9L/0+9yrEqgMprxFUNVAls45Fz8vd2c4YkEC3cmSQtXpkj93271mZBxGkbzA3YKMnp/chaskmZiIIcgx0KGo42E60aV0o+ue0yaxB0TbMEtdO5PU/3aSzdGlSS925uLRFh+f/ziC8TLfd0raOuP/PrZrUgXyCWqp6ftkVlqNBkjQURv1qyX47+myrLLOU34y7zKPsBx8+JKFgx2KESoUv9ivLGwBYqYzOse12Hj0P564f7OknbWubGXXseuaqhauzF1NZdX69WQUQg+Xj+HjlxPk314nSsU0EFPa//uUP6fbRE9S/hNpTktJbV49SkGTJAZy6m+/XYiYiKAoMdKjH+06GWLHiqp7Wfx1OlIsPk66HtpVFCaUlMTlMBT6AECcg0fb30gLr+6g3NZerwzvLmoJZSNjpc9S3BwMtyszpQJjpC6lWKVdfZt0NEwSigg51XXnlFlSaMlyZNmljvT0tLkxEjRkjFihWldOnSMnjwYDl5MnD7KCh4oHH5u3s7SfVypWT/6RS5e+IauZhuDib8BQ3TL03fqhZC7N00QXo1TVDN27d2rCXzn+opt3aoqUp4egFFI72h6maWsogoCAV0sAPNmzeXEydOWC9Lly613vfEE0/IjBkz5JdffpFFixbJ8ePHZdCgQX49Xio5qsRFy/fDOqopMKzfc9+3a+S4H3dHx6rIqw6cleiIUHn5+mY291UuEyVvDm4lX9zVXmKjckfu8/btlKQm5b+2nJBGL/6lVtsmouAW8MFOeHi4VKlSxXqpVMk8LXP+/Hn5+uuv5f3335errrpK2rVrJxMnTpTly5fLypUr/X3YVELUq1xavr2no8RGhsnK/Wel5zv/yJgZ2+W0j8taWBAQfTm6p8jYk+MKa2bn2PmAH6n3lp/XHlGLSE7fYF6OgIiCV8AHO3v27JFq1apJvXr1ZMiQIXL48GF1+7p16yQzM1N69+5tfSxKXLVq1ZIVK1b48YippMHo9k8PdJHO9SpIRnaOfLPsgPR4e6G89/cuueCjVYnf/3u3CrDQe3OfkwZsR5pVLaum1bDDO/qQgh3WIFp36F91fdtxlu6Igl1ABzudOnWSSZMmyezZs2X8+PFy4MAB6d69u1y4cEESExMlMjJSypUz/0WqJSQkqPucSU9Pl+TkZJsLUWG0qB4nP97fWZW1UBLCBNQnC/bKgE+XyZGzRTutdTI5TX5YeUhdHzOghVpbyJOm60YJZUrMCPq+UxetDdvouUrN8G+/FRGV4GCnb9++cvPNN0urVq2kT58+MmvWLDl37pz8/PPPhXrecePGSVxcnPVSs6Z5E0iiwkADffeGleX3EV1lwh2XSbW4aPVGOvB/y2VLEW7FMHnlIdWUjJHybpZFET2hd0Dfciz4+3bWWrI6gKrdjhOBt14SEZWQYCcvZHEaNWoke/fuVf07GRkZKvgxwjQW7nNm1KhRqudHX44cOVLER04lLei5tkVVmTaiqzStWlaVl/7zxQr5x7IZqTelZ2XLlNXm0u7Qy82LHXoqdyXl4M/s6BKWtp2lLKKgVqyCnYsXL8q+ffukatWqqiE5IiJC5s+fb71/165dqqenS5cuTp8nKipKypYta3Mh8raEstHy8wOd1YrMKGsN+3ataor1pr+2JMrpixlSpWy0XNPcvMu7p6x7ZB0tfJPyukNn5bpPlqhNVZMCsAdIBzvoVYJtx31fysbk2+jft8qJ8/6b4CMqKQI62Hn66afVSPnBgwfVlNXAgQMlLCxMbrvtNlV+GjZsmDz55JOycOFC1bB8zz33qECnc+fO/j50IuuCfd/c3UEGta0u2TkmtcXEt8sPeu35J1meC7u729vewh3o2YkMD1UrQx8uZJ/RhEX7ZeuxZPl88X7p9vZCtX3FoTMpEgiwAOSB0+ZjubNLbb8FO5ja+27FIbnti5Wq74qISmiwc/ToURXYNG7cWG655Ra1eCDGyitXNm/i+MEHH8h1112nFhPs0aOHKl/99ttv/j5sIhsIIN67pbU80KOe+vzlP7bJVEvpqTA2HTmnNiSNDAuV2zrV8spxNq9mznQs3WveQ8sTmdk5snLfGXW9cUIZNd49ZdVhufLdf+Spnzf5ffHF9YfNpe+G8aXl8voV1fVdiRfUcfsy4Fp32JxdOngmVW77cqUkXWDAQ1Qig52pU6eqhQIxPYXAB5/Xr1/fen90dLR89tlncvbsWUlJSVGBTkH9OkT+6uN5rm8Tua+beSx81LQtMm3D0UI957crzFmd/q2qSqXSUV45zmubm//7mW7ZHd3TIOxCepaUj4mQWY91l58f6KJ2mc8xifzf+qMy6H/L/JrlWXvorPrYvk55qVk+RspEhaslA/YmXfTZMSzYmaQao+tWijWvwn0qRYZ8ucrn6zMRlRQBHewQBVvA80L/pnJH51rqjQ5ZjllbTqj7sJno54v2yQ2fLpXmo2fL0j3OMyt4U5y56YRXGpONbmxbXbA5/JqD/8rhM56VspZYjv3yBpXU2j0d61aQSfd0lF8f7KJWct598qIM+GyZLCtE9qgw1lv6dS6rVV5tp9HUks3yZSkLu9EDtu6Ycn8n1XO1J+mi3PHVKjmbkuGz4yAqKRjsEPk44BlzQwu5uV0Nlel49McNKsDp9tZCGffXTtUcnJKRrRpXnZVVflpzRGUjMC7epqbtWlOFbaru2sA8vj7Nw+zOkj2n1Mceecbg29epIDNGdpPWNcvJudRMueub1TJx2QGfrtiM6bVNlmkz7FwPunTnq8UF0zKzZfFuc6B3dbMEqV0xVgU88WWiZGfiBbXtSElZxZrIVxjsEPkYsgnYpwp/1WN9HAQ4ISEiXepVlDEDmkvF2Ei1Pg/6XOzJys6xLiLozayONsiyKzrKbO6+6aK5WQcT3Rqae+vy7if20/DO1obtV2dsly+X7BdfQfYGPUTYzwwlJGheLc6nmZ0V+87Ipcxslc3RgRa2HZlyf2cpFRGmeorWW/p5fL2q9Pt/75KFRbBEApG/Mdgh8gOUd9C0/Hy/JirAWfV8L/lxeGe5q0sdeeLqRuoxH87bLedT8283MWPzcTlxPk0FRejX8bY+zatITGSYapzdcOSc22/kCGLqVTb3otgTHRGmXvuTltf51ZIDKoDzhXUHc0tYyLKBDji2H09Wb/hFba6lhNW7Wbz1GKBBfGnp19L88/x5TeH6uTyxbN9p+XjBXnn2183MLPnB39sSpfvbC2TNQXNPGXkXgx0iP8Go+PAe9VWAE18m2nr7rR1qqkmhf1Mz5dOFe/KtX/P8b1vV9Ts61/Zoa4iCxESGWxuVf1t/1KMSVndLKcwRvMk/eEV9FbAlXUiXf3aZv85X6+ugOdkYZGASDVNihR25LwiCqfk62Gmaf12k/3Qwr+Y+c/NxSfHx1NpOyyrS+HkcPx+4k2EIBo6fC761iX5bf0yOnL0ks7c63+6IPMNghyjAhIeFyvP9m6rr3y4/ZJ1c2nEiWe6ZuEaVQK5oVFlGXNmgyI5h0GU11MeZm0+oPhdX6ZF1bJtREAQYA9uaS2Y/eXmxRXuQrdDbROh+HR10YkTeF6WsrcfPy8nkdImNDJMulrF3ow51yqvyGvq2/txsbkD3ld0nc7fM2OCHMpor0Lh/84QV8tDk9RJs9PnHsAJ5H4MdogDUs1Fl6d6wkmpCfmv2ThXw3Pn1arV5Jd6oJ9zRTgULRQVvxAllo1Qj8cKdrmVdML116EyqhIeGSGc7b+T26EwGRrGLep0Z/NWMKbaIsBBpWd3cp6P5qkl53nZzVqdHo8p2s3LIeN3c3hxoenu17YLsNozeb7SsRRRodH8XVp++kJa/xFtcoWn9oOWPGvyeetvMzcfluf/b7NYfLsGGwQ5RAI+pYwx81pZEuWnCCvVG3aRKGflmaAe1S3lR9xRhDB1cXQ9oyd5T1n6Y0lHhLn1Nw4Qy0rZWOdXngzR+UVp3+Kx1h3r0DdkPdoo2szN3R5LDEpZ202U11PlHFspXa/8g67XXkNnBYpWBZm/SBVm02/w7hpaiYNrDDess6XYxb2d2UDp9+fdtMnXNEVlg+f0riRjsEAWoJlXKWjMfpy6kS+2KMfLdsI4SFxPhk+8/qG0Na9blXGrBa78ssYxTu7vz+n/am1/jz2uOFGlj7FpLc3J7QwlLa+aDiSy8iaEUiQD2yibxDh8XXzZaZfbgFy9ld9DnMmzSGpm91X5p7Ni5S6p0pm05dt6nK0q74ptlttusBGqpzRN7knIDTWRvMdXoLVjO4Ixl7SZcL6kY7BAFMExmYUy6aly0/DCsk00jc1FrXKWM2igzM9skv647qv4BvpSRrbIweWGaavk+3a/jXrBzXetqavoL4/a6p8YdSM3/vvGYzNmWqMoBBTUnG/t1tKZVy6jxf2TPimrj0vmWv6rb166gfqbO3GIJcrHidGGCDkzzjfpti+pzmb8zST6av9fu4/acNGeQ0BhfNjpc0rNy1BYahckmeHOy7d+UDGuzfB/LhrcbArTUVth+KW9nd5ZaMq6wM9H3e8AFCtdyzUTkFwhuFv23pyprYErK17DmzvY/k+X1P3eoi4YtFh64op6aJkPv0OZj59VfpHijbGXZPd1VKHn1b1lVfll3VKauPiId6lRwq2EVCzAiUNLHdW2LKnJDm2rqebB1BZqmF+85bf2r9jI7wQ7Obf3KpVXZCNkdZFeKatVkjJwX5Kom8VKpdKTa0X7hziS5xjId5ypkyNBcjnWMjFtQ7EpMltSMrHy/S/rNtlGVMmotJKyCjWUHUPJzF87hA9+vlfDQUJn5aLdCb1ALP645LGmZOarc+MAV9WXOtpOq1IbXaRzfL652JdqWK9G3o9d/Kqyle8371AEzO0QU0Dun+yPQ0VNZevE9I+x99e7fu+W6T5bI2oNnrdtbYPVlBGbu0uU6bJ/hSuMpdgkfOWW93PH1KhXoYG8wZL9wXAia0MzddPRs+c8XK+WTBXtV0AN9W1RxmB0ryiZlvKaV+88U2K+jIUDQE3GeNCq/8sc2eeTHDSrQwZpHWMgRDedItmyx0+uCLTygUXwZaWtZkdtemQhZtIcnr5MRk9dbd47Pu84S9j7bdypFdp28oBqJCwuZre+WmxfRvLdrXfVzwua3KM0URTOvP8tYCHC9mdnBz2v1gdxgB0sr+HpJg0DBzA4ROYRyy8Kne6q/oLHaM1YfxpsP1sV5beZ29SaJ5uky0eEe9etoKC3hTRmNmjM2nZDbHezijjfY/1t3VCYtP6jWxUFchXWKnrymkZSODFe9KX9sOi5/bjmhJslw/N0aVFLHhfJa1Tj7Cx0C3kR/33jcpm8HrxslnbwNze76YeVhVQ7Emj5YLdkVt7SvIV8s3i8Ld52SBTtPSlhoqKRnZqvjaZRQRpUZHQVWP1hW336sV0N5+Mr6avIL24rojEinehXtvtk2Sihtfa32mpTnbU9SDfMwd/tJefCKevLwlQ3U1+Dn8txvm9XrxM8FgdXK/WelXW3XM3X2/LU1URKT01RAe13rquq1NKtWVh3fhiP/Sq2KMVKcoTSs13e6snG8CtaP/uudIA6lW2TEKlk2Ckbwiyxe21r5s5vBjsEOERUIpQKMbOuSBCa1sJP5uFk71Ro5F9LMfy32cGF9HUfPj0Zl7A82ZfUhFXiUjg5XZSlsr4E3VvQN6b4bwJv36ze2sCm14E0cl5evb66yP1jFGV/vCl02wCaoL/++VWUmEMxhY84X+zeV+7rX87hvZvw/5l6ZEVfWd/nrGsSXkctqlVPbR9w7aa3NfdhWYsWoq6RcTP7en9UHzqq+qjoVY6yrcUObmuWtwY4Remv01FfDhNJSIdb8xojAE8dubIjXfTN488QbJ1ZcnrbxmHRrUFl+XG0OsFCSbF0zTt6YtVNlegq7HtQ3Sw+oj3caFtHEz14FO4fPyYA25qnBooAel8TzadKzccGlR0/tO3VRTZchMMe+ceZgxzuZHb3ZbrcGFVUmbMmedFXKYrBDROQivNG+dVMr1dfzzpxdKjNTs4Lnf2WjbIPn2XosWe2Kbg/iFqxRc3O7mqok5SiQQR+Ru8eiy1h4E/92hblsoiGTNKxbXY/6QyYs3qf6mbBswA2t3XtjfuqaxqoklWMyqTf6qIhQ2Zd0UT0f+pCwv1peyyw9Gth13khvGJs32MEkVmpGtgpmsSkpAlpM/mHNpE1Hz6nzrScC/7GMfk8d3ln2nLwgY2ZuV6UkHeg81LO+/PeaxrL31EUV7Kw9dFZlAz1dEwrBLY4XZashnXOzfViuYNJycXs7E3egt+m2L1aqlczfuamV3GyZGvQ23QiO5nD9O+ut8pwuL3drWFn1a6EXqzCN58UZgx0iKhRkUn596PJCP0/lMlHy3z6N1QTSxbQsVabCBeUQlFcGX1ZDZZSwM3tRBW9PX9NIZVLwxoNSUd3KsTLky1WqrIB1XfCXtzuQXcLO7oDX5m4/E3qg5j55hc1t4/7aIZ8v2i//7EyyG+zoqbjL8yzs2KpGnAoWsa8ajkufR13CqleptDVzh8AIwQ4CDR3sYOINGSOcA5TjcMF9Hy/Yo3qtRvRsILd2NAckOH/YCgTZBARM7jSdY3FJlL/Q44TmbBjQppq1FKPXcoLtx8+rCbzClhntmbbhmAp04IXpW1XZ0N3me1fstpx/PH+N8uYy65F/UwvdfI2sHAYHoFuDSqKfCcsf+BpKq+g99CcGO0QUMDBpg4u3e2ZcNfKqhvluu6ppvNq6AW/o7gY7H8/fo3omsLYPJqy8oWejeBXsYIE9lKCM2S1kpfTETZc8fTmxUeEqgMP9KP9gas3YnIwSloZgB/1LxiyQXvTxpsuq2zznqL5N1cUIb9Kd61VUvVMoZbkS7CDDdN+3a/O9GZePibD5nQAEBTqYQo+VveUECgO/d5Ms6/rokt2D36+TPx7pZhN0eYN17D+hjHXzXGTaEGgVtESBMyv2n1blMQSlVeKipUlVc48XyrO+nmK74+vVkoqhhptbu/3fkLdwGouIAhb+QfZVoOMIelAAb9zuLHqIZmqsWgvP9m3itTcXbGKKcX280WPxP6Pl+8wlrKZVy0pFO2/K9kpZ1rFzy/5goHs6MJGF14wAZPuJZFXqut5ONskevWWInkIryLT1R9X3wWlCSRFlwy/vai///PdK9YZthHOJUlbe1+ItKAXuSbqo9jD7Y2RXqVcpVm2OiglArCnlTdbzH29uDo8vY/65HSnkprQoWemsDuAcIrOIxn3sz+Yr2LQV05AobVYt57t1wvJisENE5AQmZNAQrEtZrnp/7m5V9kFGx50yTkFQatJvYHl3i19uaUjt6mBvstxg5998mQWUCo2LLKJPBtkFTAph0gp6NUmw2xRtT5d6Fax9N67sybTYsgL3mBuay5+PdpeXrmsmVzdLkLhS9ssfxoDM23Tp8aZ2NaRauVLyxV3tVOCD8hqa6L0FY+B68koHm7pvp7ATWbo5GaVQQM8XgjbY4eHiggh80bDvDiz2Cchu+nJR1LwY7BAROYF9yFDKApSy8kIpafqGYzJ19WF1P5pCsS3DjE3HVZYCvTredmUTcx/Nwl1JdjM7+g0urzaWbAjW2kEgZjuJlZvZ0ePdepuN6RuPq+uD25nX/nEFFmlEyQdlyII2FkVPx3pL0HJFI9fKfTpw8/ZKygdPp8gCy3kdenkd62Tce7e0Ude/XnpALW/gDcgeAc5TeUvJyti34ylkhQ6eSVWZnM6WoBP0cgWeNiljKYTLXpurfrddNXurOdjp4+bCmN7GYIeIqBClrPGL9snjP22U537bIg9PNi90+OAP69V9A1pXUyUlb9MBAZp/9V/aeINDFga7zneoaz+T1DC+jMpQYB8sBDnIHlzKzFZZnNp5ptd0MIHXh54V9I9guQFXmft2zMexooBSFvp6sizj8q6um4OGawST6PVBU7O3fLvioOp1wWs1romEHie9dMAbf+5QU2aFlVtCzP0+NcvrzE5qobM6+BkaG4ObWn4Xd3rQpIzA+Nvl5j6m71faTis6gt8brH0FukfMXxjsEBG5Ucoy9skgYPho/h51vVPdCtKhTnk1Yl4tLlpNJD1dBFkdUA2nVcqoN+XFlnFwPYWFBlBHu87jL/2WNeKspSz9ZotlA8LzbOuge2J05geTX+5u/dDFxb4d3V/S3Y11mvAmjhWf1WvxUnYHGaZf1ppLdvd0rZvv/kd7NVQ9NVjkcPpGc8N2YWB8P2+/lDWzU4jxc2yRArrcqeF3xtNtI1YfPKv6lgABjCt7yGF9LExTtqweJzUsQZy/MNghInKjlIXJLP2X7nP/t1n9hX9Fo8pq7ZlfHrxcZj/eQ5aP6qVGxovyH3i9c/o/lpKLXl/HUb+OcXFB3dirx56Nb7a5j7OdmkH/irswkQUY53e2SeviPeaATY+5u8payvJSkzJ6k7DcAYK/7nZKgSjv3dfdHARNWLTP7qa47rBu02E4/7k9O55ldvB7qcuZeVc0b2wJdrCQobuZKSw9oCHInm3pxXGlhOXvrA4w2CEi8qCU9cOqQ2qXdpSFxg5s4fMNKXtaAgOMoJt3nbe/mGBebWrGWXtd7DUna7UqxFhHn3G/XnTRHWiIRSYEb6yOemsOnUlRa/qE5+kvcYXOPnmjSVmVaSyLSd59eR2HC1be3qm22vAWK0zP3V7wG75rmZ3S+TI7yCK6M/2nYWoOpU38XuYNWKuXK6VWJceWHvtP224+6gwazHWQ38sSZOvPHTl/KdOabWSwQ0RUDEtZ+Iv1LctUDsbK/ZGix+7t2JMME1NYiBH9EdERodYAoKDMDkpYeoNUY3OyhuCto2WKDCtWexLM6fV2nPXtYCXo3Nfj3sJzeiILU3KFzbLM2HxcLReAYAALWDqCEqFuXP7fP/tcDkjyPi45LdNaFjKef0x/Ic5CYzdWrXaXzvThvOctO4aEhFjX29l5wraUhe1YBo9fbneD14U7T6lVu6uUjZZXbmhuLWs565XCfm4IqhDIoVnd3xjsEBG5Wcp6bOpG1eSLcdo7OtX2y/HgjQybm+oxd8CIu94/ylm/D960EBtgx3hHZSx4+YZm8tbglnJPV/ObuyesfTuWzFNeSyw9Rz082EQWa8cgg4FF+HT/kSfmbT8pT/+ySV2/o0tttViiM8j8ILBEkKUzas68O2eXtHh5jvxtKP3orBp2ozeO1+PnqjesPeLB+Dn6ZKBX0wS79ze207eDktmL07eoZQJQms0bmOkS1g1tqqkyG/rCVCnLUqay5y/LhrHX+nkKS2OwQ0TkZikrI9u83xP2BnN1o9GioDeo1IvEXV7ftYDBWN6ICg9VJSt78Kb7nw618jUvu0NndtAjhB2+jTIN5Td3+3V0w7Uep/d0HBwByEOT16ksBH6+Txo2T3UECzbe2sG8Ncb4f/Y5fSyCMEy0ITh+5McN1ukke83JWnVrKcu9vh1sA7LJshZUb0tgnleTKpaJLMNaO2P/3KFW+oZVB86q1bONGaj5hm07oH/LKk5LWdhXDOVV6BMAJSxgsENE5GYpCx7r1dDv6Xndt6N1beC8OVnTAQLgNbi7Z5c7ME6OTBICRL2WjoYACA3B2BJC7zrvrjs7m7NOXy3Zb50ccxXWQ8JyAQh0rmtVVT66tY3LE2doVMZ5w+TT5qP2+5GQIXlt5nZVYkMmCKWpYZPWqADIXnNy/vFz9zI783actAaz8Q72kGtSxbaMtWTPKflra6J6LdjUF17/c4fquYHZWxJVzxWmC5tZRtf7tqjqtJS1aNcp9VoRROuv8TcGO0REbpSy3r+ltQp0hveo5+/DUW9ounEYTbOuBgzGzI695mRvMq63MzNPJkCPzWNXbk8Drj7NE+TKxpVVwPLS9K0u99AgKzFiyga1vg8yFh/+p41bGSz0aWEdJWfZnfk7ktRYPdYx+n1EN7msVjnV+zL0m9XWcXx75z93/DzVoxIWVp52pJEl2MH4PHqCXvljm/r8zs615c1BrdQkGvq/3v97l7pdj9hjE17dt2UsZc2xU8pC8KQbk33duO8Igx0iIjf0bVlVnri6kdtrzhQVvcEoVk12NWDAuif6ofaak73tulbmoODH1Yflf//szdecrHuPPIE301dvaKHKcWiCNpZgHG3RgP6UEVPWq4zLwLbV5f1b3At0tAd7mhcZxBg2GnKNkA0ZO2uHun5PtzqqV+broR2kfuVYtfM8pqYcnX9PtoxAhmy5ZfmBa5wEO2WjI6zB1KjfNsu+UylSqXSk+p1Gafa1AS2sCwfO33HS2liOdZaMrKWsPKuKY3JrgaXsFQhTWFpg/NdKREQewY7gyDQ9389253Fn0ICLgAf0x6LUu1mCPHttE3X97dm7VMnp35QMa/mnhxuLCdqDVZcfuapBvhJMXqsPnJW+Hy2RH1YeVp+j8Ro7cXuaVUIJCsESMhzYsd24svB3Kw6qySZsBTHySvOxYUuIb+/tqJqSNZSH8vJkywhkyVAqRNkw78apjkpZ83aYgxL8bHSTNIJmBDZoYH/oh/XqtaERXwdgmrWUdSC3lIXg8bvlh1TghdfYpoZ/dji3x3nLORERBTSMQuOvcndhrycEG4XJqrjjoZ71Vbbjg3m7VUCCLSLwRooyDibECuv+HvXktw3H1Po37/29S8ZYMhRw5mK6KjV9veyA+p5Yb+btm1o53EPMHXge7Ab/89qjqox2+EyKDO9R37qy9n/7NLIZqUf5a9I9HeXOr1er125v3F4HFtgxHAGEK8GYsYRVUOmoSZWy1kAHpbW8o/Yv9m+qsjMIWmBA2+p2j7F1jTjVED1r8wm1QezHC/ao86/LXv5s3s+LwQ4RUQmEv/4LygB426O9GqgyB9an0RM+hc3qaBi5f31AC7n9q1Uqw4K+JGzq+c/uU2qLD93K85/2NeXF65q6vaaPIyhnvjW4ldSuGCvvzNklXy45INM2HJMLaVmqn+qmdjXzfQ32qFr23JWql8ceNHRjkUX0IWHCCmvvOIOpNl06urpZwaWjJpa1dhATISjMG5SgFwxTaWNmblfHoacQ8+rXsqoKdl6dud16fsvFRMj93etZV5oOFAx2iIjIJ5BxwC7wyPB8tfSAuq27ByPnjmD1aDQbo2/nyZ/N6+ZoLaqXlaeubmzdZsPbr2vElQ1U+em/v2yW0xfNm7O+fH1zh1kZZ+sh4WsQ4GBjV/Tt6GBn67Hz8uG8PXJH51rWZQcA4+wo3WHF63a1zQstFjRVeEWjyiqr18JBGfOuLrVVo3KdSrHWlbTtBTvj/tqpAh1M1CG7dleXOg73ZvOnwDsiIiIKWggMXujfVPWvHD6TWuBeXu7Cc6OPBI3ICKQwno83dkej2N40oE11FZg8/9sWFVR1dLD7vCsQOCHYwUQWngd9McO+XaPWVEJ/zjd3d7DufaVLWGhWd6XkFRsVrnqHnEHD9jOWPitHUMr67PbLVFA0uF2NgAxytMA9MiIiCko6E1IU4stEy7Jnr1LX/dEzglWssQlsYZnX2jmjmpSRCXv4h/Uq0EF/EBqRh3+/Vr4f1kn13Lgycl5U+reyX+IKNJzGIiKioIIgJ5CaYz1Rs0LuhqCvztimNp3FXmh/PtpdlZ+wRcY9E1erdXDwGIze+6rZvDhisENERBRg9Oay2H9q8qrDqpn441vbqnH3z+9sp3pzsEDhEz+Ze5MQ6MREsljjCIMdIiKiAM3s6PHvp65uZG2uRlCDnh3jVgz+KGEVJwx2iIiIAjSzo3cOz9vjhEUAvxvWUa3Vg0koV0bOSzLmvIiIiAJMfJkote1DSkaWvHtLa7sLBWJ1ZvTwmDcadTzKTgx2iIiIAg6Cmy/uau/SooaMcwrGMhYREREFNQY7REREFNQY7BAREVFQY7BDREREQY3BDhEREQU1BjtEREQU1BjsEBERUVBjsENERERBjcEOERERBTUGO0RERBTUGOwQERFRUGOwQ0REREGNwQ4REREFNQY7REREFNTC/X0AgcBkMqmPycnJ/j4UIiIicpF+39bv444w2BGRCxcuqI81a9b096EQERGRB+/jcXFxDu8PMRUUDpUAOTk5cvz4cSlTpoyEhIR4NeJEAHXkyBEpW7as156X8uO59h2ea9/hufYtnu/id64RwiDQqVatmoSGOu7MYWYHjUuhoVKjRo0ie378IPkfjm/wXPsOz7Xv8Fz7Fs938TrXzjI6GhuUiYiIKKgx2CEiIqKgxmCnCEVFRcnLL7+sPlLR4rn2HZ5r3+G59i2e7+A912xQJiIioqDGzA4REREFNQY7REREFNQY7BAREVFQY7BDREREQY3BThH67LPPpE6dOhIdHS2dOnWS1atX+/uQir1x48ZJhw4d1GrX8fHxcuONN8quXbtsHpOWliYjRoyQihUrSunSpWXw4MFy8uRJvx1zMHjzzTfV6uKPP/649TaeZ+86duyY3HHHHep8lipVSlq2bClr16613o9ZktGjR0vVqlXV/b1795Y9e/b49ZiLo+zsbHnppZekbt266jzWr19fXnvtNZu9lXiuPbN48WK5/vrr1WrG+Pdi+vTpNve7cl7Pnj0rQ4YMUQsNlitXToYNGyYXL1708IhsvzkVgalTp5oiIyNN33zzjWnbtm2m+++/31SuXDnTyZMn/X1oxVqfPn1MEydONG3dutW0ceNGU79+/Uy1atUyXbx40fqYBx980FSzZk3T/PnzTWvXrjV17tzZdPnll/v1uIuz1atXm+rUqWNq1aqV6bHHHrPezvPsPWfPnjXVrl3bdPfdd5tWrVpl2r9/v2nOnDmmvXv3Wh/z5ptvmuLi4kzTp083bdq0yXTDDTeY6tata7p06ZJfj724GTt2rKlixYqmmTNnmg4cOGD65ZdfTKVLlzZ99NFH1sfwXHtm1qxZphdeeMH022+/IXI0TZs2zeZ+V87rtddea2rdurVp5cqVpiVLlpgaNGhguu2220yFxWCniHTs2NE0YsQI6+fZ2dmmatWqmcaNG+fX4wo2SUlJ6j+qRYsWqc/PnTtnioiIUP+AaTt27FCPWbFihR+PtHi6cOGCqWHDhqa5c+earrjiCmuww/PsXc8++6ypW7duDu/PyckxValSxfTOO+9Yb8PPICoqyvTjjz/66CiDQ//+/U333nuvzW2DBg0yDRkyRF3nufaOvMGOK+d1+/bt6uvWrFljfcxff/1lCgkJMR07dqxQx8MyVhHIyMiQdevWqRSdcf8tfL5ixQq/HluwOX/+vPpYoUIF9RHnPTMz0+bcN2nSRGrVqsVz7wGUqfr3729zPoHn2bv++OMPad++vdx8882qPNu2bVv58ssvrfcfOHBAEhMTbc439gNCeZzn2z2XX365zJ8/X3bv3q0+37RpkyxdulT69u2rPue5LhqunFd8ROkK/y1oeDzeP1etWlWo78+NQIvA6dOnVV04ISHB5nZ8vnPnTr8dVzDuVo8ekq5du0qLFi3UbfiPKTIyUv0Hk/fc4z5y3dSpU2X9+vWyZs2afPfxPHvX/v37Zfz48fLkk0/K888/r875o48+qs7x0KFDrefU3r8pPN/uee6559SO2wjOw8LC1L/VY8eOVX0iwHNdNFw5r/iIYN8oPDxc/TFb2HPPYIeKddZh69at6q8y8q4jR47IY489JnPnzlUN9lT0gTv+mn3jjTfU58js4Hd7woQJKtgh7/n5559l8uTJMmXKFGnevLls3LhR/dGEplqe6+DFMlYRqFSpkvqLIe9kCj6vUqWK344rmIwcOVJmzpwpCxculBo1alhvx/lFGfHcuXM2j+e5dw/KVElJSXLZZZepv6xwWbRokXz88cfqOv4a43n2HkynNGvWzOa2pk2byuHDh9V1fU75b0rh/fe//1XZnVtvvVVNvN15553yxBNPqElP4LkuGq6cV3zEvztGWVlZakKrsOeewU4RQOq5Xbt2qi5s/MsNn3fp0sWvx1bcoe8Ngc60adNkwYIFanzUCOc9IiLC5txjNB1vGjz3ruvVq5ds2bJF/dWrL8g8INWvr/M8ew9KsXmXUEBPSe3atdV1/J7jH3vj+UYpBn0MPN/uSU1NVT0gRvjjFP9GA8910XDlvOIj/oDCH1sa/p3Hzwa9PYVSqPZmcjp6ji7zSZMmqQ7z4cOHq9HzxMREfx9asfbQQw+p0cV//vnHdOLECeslNTXVZiQa4+gLFixQI9FdunRRFyoc4zQW8Dx7d7w/PDxcjUXv2bPHNHnyZFNMTIzphx9+sBnbxb8hv//+u2nz5s2mAQMGcBzaA0OHDjVVr17dOnqOMelKlSqZnnnmGetjeK49n97csGGDuiC8eP/999X1Q4cOuXxeMXretm1btQTD0qVL1TQoR88D3CeffKLeDLDeDkbRsW4AFQ7+A7J3wdo7Gv7Defjhh03ly5dXbxgDBw5UARF5N9jhefauGTNmmFq0aKH+SGrSpInpiy++sLkfo7svvfSSKSEhQT2mV69epl27dvnteIur5ORk9XuMf5ujo6NN9erVU2vDpKenWx/Dc+2ZhQsX2v33GQGmq+f1zJkzKrjB2kdly5Y13XPPPSqIKqwQ/F/hckNEREREgYs9O0RERBTUGOwQERFRUGOwQ0REREGNwQ4REREFNQY7REREFNQY7BAREVFQY7BDREREQY3BDhGRHSEhITJ9+nR/HwYReQGDHSIKOHfffbcKNvJerr32Wn8fGhEVQ+H+PgAiInsQ2EycONHmtqioKL8dDxEVX8zsEFFAQmCDXZKNl/Lly6v7kOUZP3689O3bV0qVKiX16tWTX3/91ebrsWv7VVddpe6vWLGiDB8+XC5evGjzmG+++UaaN2+uvlfVqlVl5MiRNvefPn1aBg4cKDExMdKwYUP5448/fPDKicjbGOwQUbH00ksvyeDBg2XTpk0yZMgQufXWW2XHjh3qvpSUFOnTp48KjtasWSO//PKLzJs3zyaYQbA0YsQIFQQhMEIg06BBA5vv8eqrr8ott9wimzdvln79+qnvc/bsWZ+/ViIqpEJvJUpE5GXYJTksLMwUGxtrcxk7dqy6H/90PfjggzZf06lTJ9NDDz2krmPHcOzGfvHiRev9f/75pyk0NNSUmJioPq9WrZra7doRfI8XX3zR+jmeC7f99ddfXn+9RFS02LNDRAHpyiuvVNkXowoVKlivd+nSxeY+fL5x40Z1HRme1q1bS2xsrPX+rl27Sk5OjuzatUuVwY4fPy69evVyegytWrWyXsdzlS1bVpKSkgr92ojItxjsEFFAQnCRt6zkLejjcUVERITN5wiSEDARUfHCnh0iKpZWrlyZ7/OmTZuq6/iIXh707mjLli2T0NBQady4sZQpU0bq1Kkj8+fP9/lxE5HvMbNDRAEpPT1dEhMTbW4LDw+XSpUqqetoOm7fvr1069ZNJk+eLKtXr5avv/5a3YdG4pdfflmGDh0qr7zyipw6dUoeeeQRufPOOyUhIUE9Brc/+OCDEh8fr6a6Lly4oAIiPI6IgguDHSIKSLNnz1bj4EbIyuzcudM6KTV16lR5+OGH1eN+/PFHadasmboPo+Jz5syRxx57TDp06KA+x+TW+++/b30uBEJpaWnywQcfyNNPP62CqJtuusnHr5KIfCEEXco++U5ERF6C3plp06bJjTfe6O9DIaJigD07REREFNQY7BAREVFQY88OERU7rL4TkTuY2SEiIqKgxmCHiIiIghqDHSIiIgpqDHaIiIgoqDHYISIioqDGYIeIiIiCGoMdIiIiCmoMdoiIiCioMdghIiIiCWb/D0vfrjUM6V2BAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_losses(train_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "73276"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_size"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Inference\n",
        "\n",
        "Since our dataset is very small, it won't work very well, but just for the sake of demonstration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD3K8T6B4YJp",
        "outputId": "e057405b-1f78-431c-fa71-032a738fb848"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['[CLS]', 'what', 'is', 'your', 'perspective', 'on', 'death', '[SEP]', 'how', 'can', 'i', '[MASK]', '[MASK]', 'writing', 'skills', 'and', '[MASK]', 'style', '[SEP]']\n",
            "masked tokens (words) :  ['my', 'blog', 'improve', '[PAD]', '[PAD]']\n",
            "masked tokens list :  [61384, 19034, 42812, 0, 0]\n",
            "masked tokens (words) :  ['start', 'start', 'i', 'start', 'start']\n",
            "predict masked tokens list :  [np.int64(49971), np.int64(49971), np.int64(21670), np.int64(49971), np.int64(49971)]\n",
            "1\n",
            "isNext :  False\n",
            "predict isNext :  True\n"
          ]
        }
      ],
      "source": [
        "batch = make_batch()\n",
        "# Predict mask tokens ans isNext\n",
        "input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(batch[2]))\n",
        "print([id2word[w.item()] for w in input_ids[0] if id2word[w.item()] != '[PAD]'])\n",
        "\n",
        "_, logits_lm, logits_nsp = model(input_ids, segment_ids, masked_pos)\n",
        "#logits_lm:  (1, max_mask, vocab_size) ==> (1, 5, 34)\n",
        "#logits_nsp: (1, yes/no) ==> (1, 2)\n",
        "logits_lm = logits_lm.cpu()\n",
        "logits_nsp = logits_nsp.cpu()\n",
        "\n",
        "#predict masked tokens\n",
        "#max the probability along the vocab dim (2), [1] is the indices of the max, and [0] is the first value\n",
        "logits_lm = logits_lm.data.max(2)[1][0].data.numpy() \n",
        "#note that zero is padding we add to the masked_tokens\n",
        "print('masked tokens (words) : ',[id2word[pos.item()] for pos in masked_tokens[0]])\n",
        "print('masked tokens list : ',[pos.item() for pos in masked_tokens[0]])\n",
        "print('masked tokens (words) : ',[id2word[pos.item()] for pos in logits_lm])\n",
        "print('predict masked tokens list : ', [pos for pos in logits_lm])\n",
        "\n",
        "#predict nsp\n",
        "logits_nsp = logits_nsp.data.max(1)[1][0].data.numpy()\n",
        "print(logits_nsp)\n",
        "print('isNext : ', True if isNext else False)\n",
        "print('predict isNext : ',True if logits_nsp else False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Trying a bigger dataset should be able to see the difference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "save_path = f'./app/models/model.pt'\n",
        "torch.save(model.state_dict(), save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "pickle.dump(data, open('./app/models/data.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
